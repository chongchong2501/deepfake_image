# =====================
# æ·±åº¦ä¼ªé€ å›¾åƒæ£€æµ‹ - æ·±åº¦å­¦ä¹ ç‰ˆæœ¬ (ä»å¤´è®­ç»ƒ)
# =====================

# =====================
# 1. å¯¼å…¥ä¾èµ–
# =====================
import os
import cv2
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.models import efficientnet_b0
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm.auto import tqdm

# =====================
# 2. è®¾ç½®å‚æ•° (æ·±åº¦å­¦ä¹ é…ç½®)
# =====================
BASE_PATH = '/kaggle/input/deepfake-and-real-images/Dataset/Train'
IMG_SIZE = 256
LEARNING_RATE = 1e-3  # ä»å¤´è®­ç»ƒä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡
EPOCHS = 60  # ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šè½®æ•°
WEIGHT_DECAY = 1e-4  # æ·»åŠ æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ

# å¤šGPUè®¾ç½®
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_GPUS = torch.cuda.device_count()
print(f"ğŸš€ æ·±åº¦å­¦ä¹ æ¨¡å¼ - ä»å¤´è®­ç»ƒ")
print(f"å¯ç”¨GPUæ•°é‡: {NUM_GPUS}")
if NUM_GPUS > 1:
    print(f"ä½¿ç”¨å¤šGPUè®­ç»ƒ: {[torch.cuda.get_device_name(i) for i in range(NUM_GPUS)]}")
    BATCH_SIZE = 64  # åŒGPUæ—¶å¢åŠ batch size
    NUM_WORKERS = 8  # å¤šGPUæ—¶å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
else:
    BATCH_SIZE = 32
    NUM_WORKERS = 4

print(f"Batch Size: {BATCH_SIZE}")
print(f"Num Workers: {NUM_WORKERS}")
print(f"Learning Rate: {LEARNING_RATE}")
print(f"Epochs: {EPOCHS}")

# =====================
# 3. æ„å»ºæ ‡ç­¾ DataFrame
# =====================
classes = ['Real', 'Fake']
filepaths, labels = [], []

for label_idx, cls in enumerate(classes):
    folder = os.path.join(BASE_PATH, cls)
    for img_name in os.listdir(folder):
        filepaths.append(os.path.join(folder, img_name))
        labels.append(label_idx)

labels_df = pd.DataFrame({'filepath': filepaths, 'label': labels})
print(f"æ€»å›¾ç‰‡æ•°: {len(labels_df)}")
print(labels_df.head())

# =====================
# 4. æ•°æ®åˆ’åˆ†
# =====================
train_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['label'], random_state=42)

# =====================
# 5. æ•°æ®å¢å¼º & é¢„å¤„ç† (æ·±åº¦å­¦ä¹ éœ€è¦æ›´å¼ºçš„æ•°æ®å¢å¼º)
# =====================
train_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.2),  # æ·»åŠ å‚ç›´ç¿»è½¬
    transforms.RandomRotation(degrees=15),  # æ·»åŠ æ—‹è½¬
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.RandomGrayscale(p=0.1),  # éšæœºç°åº¦åŒ–
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    transforms.RandomErasing(p=0.1)  # éšæœºæ“¦é™¤
])

val_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# =====================
# 6. è‡ªå®šä¹‰ Dataset
# =====================
class DeepfakeDataset(Dataset):
    def __init__(self, df, transform=None):
        self.df = df
        self.transform = transform
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        img_path = self.df.iloc[idx]['filepath']
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        if self.transform:
            img = self.transform(img)
        
        label = self.df.iloc[idx]['label']
        return img, label

train_dataset = DeepfakeDataset(train_df, transform=train_transform)
val_dataset = DeepfakeDataset(val_df, transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
                         num_workers=NUM_WORKERS, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
                       num_workers=NUM_WORKERS, pin_memory=True)

# =====================
# 7. æ„å»ºæ¨¡å‹ (EfficientNet-B0 ä»å¤´è®­ç»ƒ)
# =====================
print("ğŸ”¥ åˆ›å»ºEfficientNet-B0æ¨¡å‹ (æ— é¢„è®­ç»ƒæƒé‡)")
model = efficientnet_b0(weights=None)  # ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä»å¤´è®­ç»ƒ

# ä¿®æ”¹åˆ†ç±»å™¨
model.classifier[1] = nn.Linear(in_features=1280, out_features=2)

# æƒé‡åˆå§‹åŒ–
def init_weights(m):
    if isinstance(m, nn.Linear):
        torch.nn.init.xavier_uniform_(m.weight)
        m.bias.data.fill_(0.01)
    elif isinstance(m, nn.Conv2d):
        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

model.apply(init_weights)
model = model.to(DEVICE)

# å¤šGPUæ”¯æŒ
if NUM_GPUS > 1:
    model = nn.DataParallel(model)
    print(f"âœ… æ¨¡å‹å·²é…ç½®ä¸ºå¤šGPUè®­ç»ƒï¼Œä½¿ç”¨ {NUM_GPUS} ä¸ªGPU")

# =====================
# 8. æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ (æ·±åº¦å­¦ä¹ é…ç½®)
# =====================
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)

# =====================
# 9. GPUä½¿ç”¨ç›‘æ§å‡½æ•°
# =====================
def print_gpu_usage():
    if torch.cuda.is_available():
        for i in range(NUM_GPUS):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)} - "
                  f"Memory: {torch.cuda.memory_allocated(i)/1024**3:.2f}GB / "
                  f"{torch.cuda.memory_reserved(i)/1024**3:.2f}GB")

# =====================
# 10. è®­ç»ƒ & éªŒè¯å¾ªç¯ + Early Stopping
# =====================
best_val_loss = float('inf')
patience = 10  # ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šè€å¿ƒ
trigger_times = 0
train_losses, val_losses, val_accuracies = [], [], []

print("ğŸš€ å¼€å§‹æ·±åº¦å­¦ä¹ è®­ç»ƒ...")
print_gpu_usage()

for epoch in range(EPOCHS):
    model.train()
    train_loss = 0
    
    # åœ¨ç¬¬ä¸€ä¸ªepochæ˜¾ç¤ºè¯¦ç»†çš„GPUä½¿ç”¨æƒ…å†µ
    if epoch == 0:
        print("ç¬¬ä¸€ä¸ªbatchçš„GPUä½¿ç”¨æƒ…å†µ:")
    
    for batch_idx, (imgs, labels) in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Train]")):
        imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
        
        # åœ¨ç¬¬ä¸€ä¸ªepochçš„ç¬¬ä¸€ä¸ªbatchæ˜¾ç¤ºGPUåˆ†å¸ƒæƒ…å†µ
        if epoch == 0 and batch_idx == 0:
            print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {imgs.shape}")
            if NUM_GPUS > 1:
                print(f"æ•°æ®å°†åˆ†å¸ƒåˆ° {NUM_GPUS} ä¸ªGPUä¸Š")
                print_gpu_usage()
        
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    train_loss /= len(train_loader)
    train_losses.append(train_loss)
    
    # éªŒè¯
    model.eval()
    val_loss = 0
    correct = 0
    total = 0
    all_preds, all_labels = [], []
    with torch.no_grad():
        for imgs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Val]"):
            imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    val_loss /= len(val_loader)
    val_acc = correct / total
    val_losses.append(val_loss)
    val_accuracies.append(val_acc)
    
    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler.step(val_loss)
    current_lr = optimizer.param_groups[0]['lr']
    
    print(f"Epoch [{epoch+1}/{EPOCHS}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}")
    
    # æ¯10ä¸ªepochæ˜¾ç¤ºä¸€æ¬¡GPUä½¿ç”¨æƒ…å†µ
    if (epoch + 1) % 10 == 0:
        print_gpu_usage()
    
    # Early Stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        trigger_times = 0
        # ä¿å­˜æ¨¡å‹æ—¶å¤„ç†å¤šGPUæƒ…å†µ
        if NUM_GPUS > 1:
            torch.save(model.module.state_dict(), "best_model_deep_learning.pth")
        else:
            torch.save(model.state_dict(), "best_model_deep_learning.pth")
        print("âœ… Best model saved.")
    else:
        trigger_times += 1
        if trigger_times >= patience:
            print("â›” Early stopping triggered.")
            break

# =====================
# 11. è®­ç»ƒæ›²çº¿å¯è§†åŒ–
# =====================
plt.figure(figsize=(15,5))
plt.subplot(1,3,1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.legend()
plt.title("Loss Curve (Deep Learning)")
plt.xlabel("Epoch")
plt.ylabel("Loss")

plt.subplot(1,3,2)
plt.plot(val_accuracies, label='Val Acc', color='green')
plt.legend()
plt.title("Accuracy Curve (Deep Learning)")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")

plt.subplot(1,3,3)
epochs_range = range(len(train_losses))
plt.plot(epochs_range, train_losses, label='Train Loss')
plt.plot(epochs_range, val_losses, label='Val Loss')
plt.fill_between(epochs_range, train_losses, alpha=0.3)
plt.fill_between(epochs_range, val_losses, alpha=0.3)
plt.legend()
plt.title("Training Progress")
plt.xlabel("Epoch")
plt.ylabel("Loss")

plt.tight_layout()
plt.show()

# =====================
# 12. æ··æ·†çŸ©é˜µ & æŠ¥å‘Š
# =====================
plt.figure(figsize=(8,6))
cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
plt.title("Confusion Matrix (Deep Learning)")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()

print("\n" + "="*50)
print("æ·±åº¦å­¦ä¹ è®­ç»ƒå®Œæˆï¼")
print("="*50)
print(classification_report(all_labels, all_preds, target_names=classes))

# =====================
# 13. æœ€ç»ˆç»Ÿè®¡
# =====================
print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡:")
print(f"æ€»è®­ç»ƒè½®æ•°: {len(train_losses)}")
print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_accuracies[-1]:.4f}")
print(f"æœ€é«˜éªŒè¯å‡†ç¡®ç‡: {max(val_accuracies):.4f}")
print(f"æ¨¡å‹ä¿å­˜è·¯å¾„: best_model_deep_learning.pth")