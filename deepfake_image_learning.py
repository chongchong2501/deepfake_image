# =====================
# æ·±åº¦ä¼ªé€ å›¾åƒæ£€æµ‹ - æ·±åº¦å­¦ä¹ ç‰ˆæœ¬ (ä»å¤´è®­ç»ƒ)
# =====================

# =====================
# 1. å¯¼å…¥ä¾èµ–
# =====================
import os
import cv2
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.models import efficientnet_b0
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm.auto import tqdm

# =====================
# 2. è®¾ç½®å‚æ•° (æ·±åº¦å­¦ä¹ é…ç½®)
# =====================
BASE_PATH = '/kaggle/input/deepfake-and-real-images/Dataset'
TRAIN_PATH = os.path.join(BASE_PATH, 'Train')
VAL_PATH = os.path.join(BASE_PATH, 'Validation')
IMG_SIZE = 256
LEARNING_RATE = 1e-3  # ä»å¤´è®­ç»ƒä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡
EPOCHS = 15  # ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šè½®æ•°
WEIGHT_DECAY = 1e-4  # æ·»åŠ æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ
MAX_VAL_SAMPLES = 6400  # é™åˆ¶éªŒè¯é›†æ ·æœ¬æ•°
# å¤šGPUè®¾ç½®
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_GPUS = torch.cuda.device_count()
print(f"ğŸš€ æ·±åº¦å­¦ä¹ æ¨¡å¼ - ä»å¤´è®­ç»ƒ")
print(f"å¯ç”¨GPUæ•°é‡: {NUM_GPUS}")
if NUM_GPUS > 1:
    print(f"ä½¿ç”¨å¤šGPUè®­ç»ƒ: {[torch.cuda.get_device_name(i) for i in range(NUM_GPUS)]}")
    BATCH_SIZE = 64  # åŒGPUæ—¶å¢åŠ batch size
    NUM_WORKERS = 4  # å¤šGPUæ—¶å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
else:
    BATCH_SIZE = 32
    NUM_WORKERS = 2

print(f"Batch Size: {BATCH_SIZE}")
print(f"Num Workers: {NUM_WORKERS}")
print(f"Learning Rate: {LEARNING_RATE}")
print(f"Epochs: {EPOCHS}")

# =====================
# 3. æ„å»ºæ ‡ç­¾ DataFrame
# =====================
classes = ['Real', 'Fake']

def create_dataframe(data_path, dataset_type):
    """åˆ›å»ºæŒ‡å®šæ•°æ®é›†çš„DataFrame"""
    filepaths, labels = [], []
    
    for label_idx, cls in enumerate(classes):
        folder = os.path.join(data_path, cls)
        if os.path.exists(folder):
            for img_name in os.listdir(folder):
                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    filepaths.append(os.path.join(folder, img_name))
                    labels.append(label_idx)
    
    df = pd.DataFrame({'filepath': filepaths, 'label': labels})
    print(f"{dataset_type}é›†å›¾ç‰‡æ•°: {len(df)}")
    if len(df) > 0:
        print(f"{dataset_type}é›†ç±»åˆ«åˆ†å¸ƒ:")
        for idx, cls in enumerate(classes):
            count = len(df[df['label'] == idx])
            print(f"  {cls}: {count}")
    return df

# =====================
# 4. æ•°æ®åˆ’åˆ†
# =====================
# åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†DataFrame
print("ğŸ“‚ åŠ è½½æ•°æ®é›†...")
train_df = create_dataframe(TRAIN_PATH, "è®­ç»ƒ")

# å°è¯•åŠ è½½éªŒè¯é›†ï¼ŒValidation æ–‡ä»¶å¤¹
val_df = create_dataframe(VAL_PATH, "éªŒè¯")

if len(val_df) > MAX_VAL_SAMPLES:
    print(f"ğŸ”„ éªŒè¯é›†åŸå§‹å¤§å°: {len(val_df)}, é™åˆ¶ä¸º: {MAX_VAL_SAMPLES}")
    # éšæœºé‡‡æ ·ä¿æŒç±»åˆ«å¹³è¡¡
    val_df = val_df.sample(n=MAX_VAL_SAMPLES, random_state=42).reset_index(drop=True)
    print(f"âœ… éªŒè¯é›†å·²éšæœºé‡‡æ ·è‡³ {len(val_df)} å¼ å›¾ç‰‡")
    
    # æ˜¾ç¤ºé‡‡æ ·åçš„ç±»åˆ«åˆ†å¸ƒ
    print("ğŸ“Š é‡‡æ ·åéªŒè¯é›†ç±»åˆ«åˆ†å¸ƒ:")
    for idx, cls in enumerate(classes):
        count = len(val_df[val_df['label'] == idx])
        print(f"  {cls}: {count}")

# æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
if len(train_df) == 0:
    print("âŒ è®­ç»ƒé›†ä¸ºç©ºï¼è¯·æ£€æŸ¥è·¯å¾„:", TRAIN_PATH)
    print("é¢„æœŸç»“æ„:")
    print("  Dataset/Train/Real/")
    print("  Dataset/Train/Fake/")
    
if len(val_df) == 0:
    print("âŒ éªŒè¯é›†ä¸ºç©ºï¼è¯·æ£€æŸ¥è·¯å¾„:", VAL_PATH)
    print("é¢„æœŸç»“æ„:")
    print("  Dataset/Val/Real/")
    print("  Dataset/Val/Fake/")
    print("æˆ–è€…:")
    print("  Dataset/Validation/Real/")
    print("  Dataset/Validation/Fake/")

print(f"\nğŸ“Š æ•°æ®é›†æ€»è§ˆ:")
print(f"è®­ç»ƒé›†æ€»æ•°: {len(train_df)}")
print(f"éªŒè¯é›†æ€»æ•°: {len(val_df)}")
print(f"éªŒè¯é›†æ‰¹æ¬¡æ•°: {len(val_df) // BATCH_SIZE + (1 if len(val_df) % BATCH_SIZE > 0 else 0)}")


# =====================
# 5. æ•°æ®å¢å¼º & é¢„å¤„ç† (æ·±åº¦å­¦ä¹ éœ€è¦æ›´å¼ºçš„æ•°æ®å¢å¼º)
# =====================
train_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.2),  # æ·»åŠ å‚ç›´ç¿»è½¬
    transforms.RandomRotation(degrees=15),  # æ·»åŠ æ—‹è½¬
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.RandomGrayscale(p=0.1),  # éšæœºç°åº¦åŒ–
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    transforms.RandomErasing(p=0.1)  # éšæœºæ“¦é™¤
])

val_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# =====================
# 6. è‡ªå®šä¹‰ Dataset
# =====================
class DeepfakeDataset(Dataset):
    def __init__(self, df, transform=None):
        self.df = df
        self.transform = transform
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        img_path = self.df.iloc[idx]['filepath']
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        if self.transform:
            img = self.transform(img)
        
        label = self.df.iloc[idx]['label']
        return img, label

train_dataset = DeepfakeDataset(train_df, transform=train_transform)
val_dataset = DeepfakeDataset(val_df, transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
                         num_workers=NUM_WORKERS, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
                       num_workers=NUM_WORKERS, pin_memory=True)

# =====================
# 7. æ„å»ºæ¨¡å‹ (EfficientNet-B0 ä»å¤´è®­ç»ƒ)
# =====================
print("ğŸ”¥ åˆ›å»ºEfficientNet-B0æ¨¡å‹ (æ— é¢„è®­ç»ƒæƒé‡)")
model = efficientnet_b0(weights=None)  # ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä»å¤´è®­ç»ƒ

# ä¿®æ”¹åˆ†ç±»å™¨
model.classifier[1] = nn.Linear(in_features=1280, out_features=2)

# æƒé‡åˆå§‹åŒ–
def init_weights(m):
    if isinstance(m, nn.Linear):
        torch.nn.init.xavier_uniform_(m.weight)
        m.bias.data.fill_(0.01)
    elif isinstance(m, nn.Conv2d):
        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

model.apply(init_weights)
model = model.to(DEVICE)

# å¤šGPUæ”¯æŒ
if NUM_GPUS > 1:
    model = nn.DataParallel(model)
    print(f"âœ… æ¨¡å‹å·²é…ç½®ä¸ºå¤šGPUè®­ç»ƒï¼Œä½¿ç”¨ {NUM_GPUS} ä¸ªGPU")

# =====================
# 8. æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ (æ·±åº¦å­¦ä¹ é…ç½®)
# =====================
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)

# =====================
# 9. è®­ç»ƒ & éªŒè¯å¾ªç¯ + Early Stopping
# =====================
best_val_loss = float('inf')
patience = 10  # ä»å¤´è®­ç»ƒéœ€è¦æ›´å¤šè€å¿ƒ
trigger_times = 0
train_losses, val_losses, val_accuracies = [], [], []

print("ğŸš€ å¼€å§‹æ·±åº¦å­¦ä¹ è®­ç»ƒ...")

for epoch in range(EPOCHS):
    model.train()
    train_loss = 0
    
    for batch_idx, (imgs, labels) in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Train]")):
        imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
        
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    train_loss /= len(train_loader)
    train_losses.append(train_loss)
    
    # éªŒè¯
    model.eval()
    val_loss = 0
    correct = 0
    total = 0
    all_preds, all_labels = [], []
    with torch.no_grad():
        for imgs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Val]"):
            imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    val_loss /= len(val_loader)
    val_acc = correct / total
    val_losses.append(val_loss)
    val_accuracies.append(val_acc)
    
    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler.step(val_loss)
    current_lr = optimizer.param_groups[0]['lr']
    
    print(f"Epoch [{epoch+1}/{EPOCHS}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}")
    
    # Early Stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        trigger_times = 0
        # ä¿å­˜æ¨¡å‹æ—¶å¤„ç†å¤šGPUæƒ…å†µ
        if NUM_GPUS > 1:
            torch.save(model.module.state_dict(), "best_model_deep_learning.pth")
        else:
            torch.save(model.state_dict(), "best_model_deep_learning.pth")
        print("âœ… Best model saved.")
    else:
        trigger_times += 1
        if trigger_times >= patience:
            print("â›” Early stopping triggered.")
            break

# =====================
# 10. è®­ç»ƒæ›²çº¿å¯è§†åŒ–
# =====================
plt.figure(figsize=(15,5))
plt.subplot(1,3,1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.legend()
plt.title("Loss Curve (Deep Learning)")
plt.xlabel("Epoch")
plt.ylabel("Loss")

plt.subplot(1,3,2)
plt.plot(val_accuracies, label='Val Acc', color='green')
plt.legend()
plt.title("Accuracy Curve (Deep Learning)")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")

plt.subplot(1,3,3)
epochs_range = range(len(train_losses))
plt.plot(epochs_range, train_losses, label='Train Loss')
plt.plot(epochs_range, val_losses, label='Val Loss')
plt.fill_between(epochs_range, train_losses, alpha=0.3)
plt.fill_between(epochs_range, val_losses, alpha=0.3)
plt.legend()
plt.title("Training Progress")
plt.xlabel("Epoch")
plt.ylabel("Loss")

plt.tight_layout()
plt.show()

# =====================
# 11. æ··æ·†çŸ©é˜µ & æŠ¥å‘Š
# =====================
plt.figure(figsize=(8,6))
cm = confusion_matrix(all_labels, all_preds)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
plt.title("Confusion Matrix (Deep Learning)")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()

print("\n" + "="*50)
print("æ·±åº¦å­¦ä¹ è®­ç»ƒå®Œæˆï¼")
print("="*50)
print(classification_report(all_labels, all_preds, target_names=classes))

# =====================
# 12. æœ€ç»ˆç»Ÿè®¡
# =====================
print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡:")
print(f"æ€»è®­ç»ƒè½®æ•°: {len(train_losses)}")
print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
print(f"æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_accuracies[-1]:.4f}")
print(f"æœ€é«˜éªŒè¯å‡†ç¡®ç‡: {max(val_accuracies):.4f}")
print(f"æ¨¡å‹ä¿å­˜è·¯å¾„: best_model_deep_learning.pth")