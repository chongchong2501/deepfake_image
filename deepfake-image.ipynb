{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3134515,"sourceType":"datasetVersion","datasetId":1909705}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =====================\n# 1. 导入依赖\n# =====================\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:23:09.236025Z","iopub.execute_input":"2025-07-31T09:23:09.236210Z","iopub.status.idle":"2025-07-31T09:23:23.603929Z","shell.execute_reply.started":"2025-07-31T09:23:09.236193Z","shell.execute_reply":"2025-07-31T09:23:23.603340Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# =====================\n# 2. 设置参数\n# =====================\nBASE_PATH = '/kaggle/input/deepfake-and-real-images/Dataset/Train'\nIMG_SIZE = 256\nBATCH_SIZE = 32\nLEARNING_RATE = 1e-4\nEPOCHS = 30\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:25:13.055063Z","iopub.execute_input":"2025-07-31T09:25:13.055832Z","iopub.status.idle":"2025-07-31T09:25:13.059903Z","shell.execute_reply.started":"2025-07-31T09:25:13.055806Z","shell.execute_reply":"2025-07-31T09:25:13.059235Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# =====================\n# 3. 构建标签 DataFrame\n# =====================\nclasses = ['Real', 'Fake']\nfilepaths, labels = [], []\n\nfor label_idx, cls in enumerate(classes):\n    folder = os.path.join(BASE_PATH, cls)\n    for img_name in os.listdir(folder):\n        filepaths.append(os.path.join(folder, img_name))\n        labels.append(label_idx)\n\nlabels_df = pd.DataFrame({'filepath': filepaths, 'label': labels})\nprint(f\"总图片数: {len(labels_df)}\")\nprint(labels_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:27:55.746080Z","iopub.execute_input":"2025-07-31T09:27:55.746787Z","iopub.status.idle":"2025-07-31T09:27:57.665598Z","shell.execute_reply.started":"2025-07-31T09:27:55.746759Z","shell.execute_reply":"2025-07-31T09:27:57.664923Z"}},"outputs":[{"name":"stdout","text":"总图片数: 140002\n                                            filepath  label\n0  /kaggle/input/deepfake-and-real-images/Dataset...      0\n1  /kaggle/input/deepfake-and-real-images/Dataset...      0\n2  /kaggle/input/deepfake-and-real-images/Dataset...      0\n3  /kaggle/input/deepfake-and-real-images/Dataset...      0\n4  /kaggle/input/deepfake-and-real-images/Dataset...      0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# =====================\n# 4. 数据划分\n# =====================\ntrain_df, val_df = train_test_split(labels_df, test_size=0.2, stratify=labels_df['label'], random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:28:00.666807Z","iopub.execute_input":"2025-07-31T09:28:00.667490Z","iopub.status.idle":"2025-07-31T09:28:00.747840Z","shell.execute_reply.started":"2025-07-31T09:28:00.667466Z","shell.execute_reply":"2025-07-31T09:28:00.747198Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# =====================\n# 5. 数据增强 & 预处理\n# =====================\ntrain_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:28:04.244498Z","iopub.execute_input":"2025-07-31T09:28:04.244748Z","iopub.status.idle":"2025-07-31T09:28:04.249923Z","shell.execute_reply.started":"2025-07-31T09:28:04.244731Z","shell.execute_reply":"2025-07-31T09:28:04.249285Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# =====================\n# 6. 自定义 Dataset\n# =====================\nclass DeepfakeDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df  \n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx]['filepath']\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        label = self.df.iloc[idx]['label']\n        return img, label\n\ntrain_dataset = DeepfakeDataset(train_df, transform=train_transform)\nval_dataset = DeepfakeDataset(val_df, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:28:10.046494Z","iopub.execute_input":"2025-07-31T09:28:10.047185Z","iopub.status.idle":"2025-07-31T09:28:10.057524Z","shell.execute_reply.started":"2025-07-31T09:28:10.047163Z","shell.execute_reply":"2025-07-31T09:28:10.056740Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# =====================\n# 7. 构建模型 (EfficientNet-B0)\n# =====================\nmodel = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\nfor param in model.parameters():\n    param.requires_grad = True  # 微调全部参数\n\nmodel.classifier[1] = nn.Linear(in_features=1280, out_features=2)\nmodel = model.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:28:14.609147Z","iopub.execute_input":"2025-07-31T09:28:14.609704Z","iopub.status.idle":"2025-07-31T09:28:15.335926Z","shell.execute_reply.started":"2025-07-31T09:28:14.609682Z","shell.execute_reply":"2025-07-31T09:28:15.335282Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 133MB/s] \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# =====================\n# 8. 训练 & 验证循环 + Early Stopping\n# =====================\nbest_val_loss = float('inf')\npatience = 5\ntrigger_times = 0\ntrain_losses, val_losses, val_accuracies = [], [], []\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    train_losses.append(train_loss)\n    \n    # 验证\n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for imgs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            \n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    val_loss /= len(val_loader)\n    val_acc = correct / total\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    \n    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n    \n    # Early Stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        trigger_times = 0\n        torch.save(model.state_dict(), \"best_model.pth\")\n        print(\"✅ Best model saved.\")\n    else:\n        trigger_times += 1\n        if trigger_times >= patience:\n            print(\"⛔ Early stopping triggered.\")\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:28:19.164218Z","iopub.execute_input":"2025-07-31T09:28:19.164541Z","execution_failed":"2025-07-31T09:32:12.621Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/30 [Train]:   0%|          | 0/3501 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e319eaaa3a444857bb0f77b1bc52b2fa"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# =====================\n# 9. 训练曲线可视化\n# =====================\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.legend()\nplt.title(\"Loss Curve\")\n\nplt.subplot(1,2,2)\nplt.plot(val_accuracies, label='Val Acc')\nplt.legend()\nplt.title(\"Accuracy Curve\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:23:23.794164Z","iopub.status.idle":"2025-07-31T09:23:23.794421Z","shell.execute_reply.started":"2025-07-31T09:23:23.794308Z","shell.execute_reply":"2025-07-31T09:23:23.794320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =====================\n# 10. 混淆矩阵 & 报告\n# =====================\ncm = confusion_matrix(all_labels, all_preds)\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(classification_report(all_labels, all_preds, target_names=classes))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:23:23.795554Z","iopub.status.idle":"2025-07-31T09:23:23.795838Z","shell.execute_reply.started":"2025-07-31T09:23:23.795729Z","shell.execute_reply":"2025-07-31T09:23:23.795740Z"}},"outputs":[],"execution_count":null}]}