{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Kaggle Multi-Model Ensemble Deepfake Detection with AMP\n",
      "PyTorch Version: 2.7.1+cu118\n",
      "Captum Available: True\n",
      "AMP Available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MECHREUO\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 导入依赖和环境设置\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "# 添加AMP混合精度训练支持\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.patches as patches\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import time\n",
    "from PIL import Image\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 解释工具导入\n",
    "try:\n",
    "    from captum.attr import LayerGradCam, IntegratedGradients\n",
    "    from captum.attr import visualization as viz\n",
    "    CAPTUM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ Captum not available. Install with: pip install captum\")\n",
    "    CAPTUM_AVAILABLE = False\n",
    "\n",
    "# 设置matplotlib使用英文字体和高DPI\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"🚀 Kaggle Multi-Model Ensemble Deepfake Detection with AMP\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Captum Available: {CAPTUM_AVAILABLE}\")\n",
    "print(f\"AMP Available: {torch.cuda.is_available() and hasattr(torch.cuda.amp, 'autocast')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "✅ AMP (Automatic Mixed Precision) enabled\n",
      "📈 Expected benefits: ~30% faster training, ~40% memory reduction\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "GPU 0 Memory: 8.0GB\n",
      "Plots will be saved to: ./works/plots\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 参数配置\n",
    "BASE_PATH = r'E:\\program\\deepfake_image\\Dataset'\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, 'Train')\n",
    "VAL_PATH = os.path.join(BASE_PATH, 'Validation')\n",
    "\n",
    "# 训练参数\n",
    "# 图像大小\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# 训练批次大小 (AMP可以支持更大的批次)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 学习率\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# 训练轮数\n",
    "EPOCHS = 15\n",
    "\n",
    "# 权重衰减系数\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# 早停轮数\n",
    "PATIENCE = 3\n",
    "\n",
    "# 数据加载器的工作进程数量\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# AMP混合精度训练开关\n",
    "USE_AMP = True  # 启用混合精度训练\n",
    "\n",
    "# 获取当前设备的GPU信息\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# AMP支持检查\n",
    "if torch.cuda.is_available() and USE_AMP:\n",
    "    print(\"✅ AMP (Automatic Mixed Precision) enabled\")\n",
    "    print(\"📈 Expected benefits: ~30% faster training, ~40% memory reduction\")\n",
    "elif not torch.cuda.is_available():\n",
    "    USE_AMP = False\n",
    "    print(\"⚠️ CUDA not available, AMP disabled\")\n",
    "else:\n",
    "    print(\"ℹ️ AMP disabled by configuration\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if NUM_GPUS > 1:\n",
    "        print(f\"Multi-GPU Training: {[torch.cuda.get_device_name(i) for i in range(NUM_GPUS)]}\")\n",
    "        print(f\"GPU Count: {NUM_GPUS}\")\n",
    "    else:\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    for i in range(NUM_GPUS):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"GPU {i} Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f}GB\")\n",
    "else:\n",
    "    NUM_WORKERS = 0\n",
    "    print(\"Using CPU Training\")\n",
    "\n",
    "# 创建输出目录\n",
    "PLOTS_DIR = './works/plots'\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "print(f\"Plots will be saved to: {PLOTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 3: 数据加载函数\n",
    "classes = ['Real', 'Fake']\n",
    "\n",
    "def create_dataframe(data_path, dataset_type):\n",
    "    \"\"\"创建数据集DataFrame\"\"\"\n",
    "    filepaths, labels = [], []\n",
    "    \n",
    "    for label_idx, cls in enumerate(classes):\n",
    "        folder = os.path.join(data_path, cls)\n",
    "        if os.path.exists(folder):\n",
    "            for img_name in os.listdir(folder):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    filepaths.append(os.path.join(folder, img_name))\n",
    "                    labels.append(label_idx)\n",
    "    \n",
    "    df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "    print(f\"{dataset_type}集图片数: {len(df)}\")\n",
    "    if len(df) > 0:\n",
    "        print(f\"{dataset_type}集类别分布:\")\n",
    "        for idx, cls in enumerate(classes):\n",
    "            count = len(df[df['label'] == idx])\n",
    "            print(f\"  {cls}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 4: 数据预处理和增强\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['filepath']\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.df.iloc[idx]['label']\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 5: 模型定义\n",
    "def create_efficientnet_b0():\n",
    "    \"\"\"创建EfficientNet-B0模型\"\"\"\n",
    "    model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "    model.classifier[1] = nn.Linear(1280, 2)\n",
    "    return model\n",
    "\n",
    "def create_resnet18():\n",
    "    \"\"\"创建ResNet18模型\"\"\"\n",
    "    model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    model.fc = nn.Linear(512, 2)\n",
    "    return model\n",
    "\n",
    "def create_convnext_tiny():\n",
    "    \"\"\"创建ConvNeXt-Tiny模型\"\"\"\n",
    "    model = models.convnext_tiny(weights='IMAGENET1K_V1')\n",
    "    model.classifier[2] = nn.Linear(768, 2)\n",
    "    return model\n",
    "\n",
    "# 模型配置字典\n",
    "MODEL_CONFIGS = {\n",
    "    'efficientnet_b0': {\n",
    "        'create_fn': create_efficientnet_b0,\n",
    "        'name': 'EfficientNet-B0'\n",
    "    },\n",
    "    'resnet18': {\n",
    "        'create_fn': create_resnet18,\n",
    "        'name': 'ResNet18'\n",
    "    },\n",
    "    'convnext_tiny': {\n",
    "        'create_fn': create_convnext_tiny,\n",
    "        'name': 'ConvNeXt-Tiny'\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 6: 单模型训练函数 (支持AMP)\n",
    "def train_single_model(model_key, train_loader, val_loader, save_path):\n",
    "    \"\"\"训练单个模型 - 支持AMP混合精度训练\"\"\"\n",
    "    print(f\"\\n🔥 Starting Training {MODEL_CONFIGS[model_key]['name']}\")\n",
    "    if USE_AMP:\n",
    "        print(\"⚡ Using AMP (Automatic Mixed Precision) for faster training\")\n",
    "    \n",
    "    # 记录训练开始时间\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 创建模型\n",
    "    model = MODEL_CONFIGS[model_key]['create_fn']()\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # 多GPU支持\n",
    "    if NUM_GPUS > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        print(f\"✅ Model configured for multi-GPU training with {NUM_GPUS} GPUs\")\n",
    "    \n",
    "    # 损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    # AMP梯度缩放器\n",
    "    scaler = GradScaler() if USE_AMP else None\n",
    "    \n",
    "    # 训练记录\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses, val_accuracies, learning_rates = [], [], [], []\n",
    "    val_f1_scores = []\n",
    "    \n",
    "    # 显存使用监控\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"🔍 Initial GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB / {torch.cuda.max_memory_allocated()/1024**3:.2f}GB\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "            imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # AMP前向传播\n",
    "            if USE_AMP:\n",
    "                with autocast():\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                # AMP反向传播\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # 标准训练\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "                imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "                \n",
    "                # AMP验证\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(imgs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                else:\n",
    "                    outputs = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                all_val_preds.extend(predicted.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = correct / total\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "        \n",
    "        # 显存监控\n",
    "        if torch.cuda.is_available():\n",
    "            current_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "            max_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "            memory_info = f\"GPU Mem: {current_memory:.2f}GB/{max_memory:.2f}GB\"\n",
    "        else:\n",
    "            memory_info = \"\"\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, LR: {current_lr:.6f} {memory_info}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # 保存模型时处理多GPU情况\n",
    "            if NUM_GPUS > 1:\n",
    "                torch.save(model.module.state_dict(), save_path)\n",
    "            else:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ Best model saved, validation accuracy: {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(\"⛔ Early stopping triggered\")\n",
    "                break\n",
    "        \n",
    "        # 每个epoch后清理显存\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # 计算训练时间\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"⏱️ Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # 最终显存清理\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(f\"🧹 Final GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB\")\n",
    "    \n",
    "    return {\n",
    "         'best_acc': best_val_acc,\n",
    "         'train_losses': train_losses,\n",
    "         'val_losses': val_losses,\n",
    "         'val_accuracies': val_accuracies,\n",
    "         'val_f1_scores': val_f1_scores,\n",
    "         'learning_rates': learning_rates,\n",
    "         'training_time': training_time,\n",
    "         'amp_enabled': USE_AMP\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 7: 可视化函数\n",
    "def plot_training_history(model_results, save_dir=PLOTS_DIR):\n",
    "    \"\"\"绘制训练历史可视化\"\"\"\n",
    "    print(\"📊 Generating training history visualizations...\")\n",
    "    \n",
    "    # 1. 单模型训练历史 (2x2 子图)\n",
    "    for model_key, results in model_results.items():\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(f'{MODEL_CONFIGS[model_key][\"name\"]} Training History', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        epochs = range(1, len(results['train_losses']) + 1)\n",
    "        \n",
    "        # Loss曲线\n",
    "        axes[0, 0].plot(epochs, results['train_losses'], 'b-', label='Train Loss', linewidth=2)\n",
    "        axes[0, 0].plot(epochs, results['val_losses'], 'r-', label='Validation Loss', linewidth=2)\n",
    "        axes[0, 0].set_title('Training & Validation Loss', fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Accuracy曲线\n",
    "        axes[0, 1].plot(epochs, results['val_accuracies'], 'g-', label='Validation Accuracy', linewidth=2)\n",
    "        axes[0, 1].set_title('Validation Accuracy', fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Learning Rate曲线\n",
    "        axes[1, 0].plot(epochs, results['learning_rates'], 'purple', linewidth=2)\n",
    "        axes[1, 0].set_title('Learning Rate Schedule', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Validation Accuracy分布\n",
    "        axes[1, 1].hist(results['val_accuracies'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[1, 1].axvline(results['best_acc'], color='red', linestyle='--', linewidth=2, label=f'Best: {results[\"best_acc\"]:.4f}')\n",
    "        axes[1, 1].set_title('Validation Accuracy Distribution', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Accuracy')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, f'{model_key}_training_history.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✅ Saved: {save_path}\")\n",
    "    \n",
    "    # 2. 多模型对比图 (四线对比)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Multi-Model Training Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "    \n",
    "    # 验证Loss对比\n",
    "    for i, (model_key, results) in enumerate(model_results.items()):\n",
    "        epochs = range(1, len(results['val_losses']) + 1)\n",
    "        axes[0, 0].plot(epochs, results['val_losses'], color=colors[i % len(colors)], \n",
    "                       label=MODEL_CONFIGS[model_key]['name'], linewidth=2)\n",
    "    axes[0, 0].set_title('Validation Loss Comparison', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Validation Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 验证Accuracy对比\n",
    "    for i, (model_key, results) in enumerate(model_results.items()):\n",
    "        epochs = range(1, len(results['val_accuracies']) + 1)\n",
    "        axes[0, 1].plot(epochs, results['val_accuracies'], color=colors[i % len(colors)], \n",
    "                       label=MODEL_CONFIGS[model_key]['name'], linewidth=2)\n",
    "    axes[0, 1].set_title('Validation Accuracy Comparison', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Validation Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 训练时长对比\n",
    "    model_names = [MODEL_CONFIGS[key]['name'] for key in model_results.keys()]\n",
    "    training_times = [results['training_time'] for results in model_results.values()]\n",
    "    bars = axes[1, 0].bar(model_names, training_times, color=colors[:len(model_names)], alpha=0.7)\n",
    "    axes[1, 0].set_title('Training Time Comparison', fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Training Time (seconds)')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for bar, time_val in zip(bars, training_times):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                       f'{time_val:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # F1-Score对比\n",
    "    for i, (model_key, results) in enumerate(model_results.items()):\n",
    "        epochs = range(1, len(results['val_f1_scores']) + 1)\n",
    "        axes[1, 1].plot(epochs, results['val_f1_scores'], color=colors[i % len(colors)], \n",
    "                       label=MODEL_CONFIGS[model_key]['name'], linewidth=2)\n",
    "    axes[1, 1].set_title('F1-Score Comparison', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('F1-Score')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, 'multi_model_comparison.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Saved: {save_path}\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_name, save_dir=PLOTS_DIR):\n",
    "    \"\"\"绘制混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'],\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontweight='bold')\n",
    "    \n",
    "    # 添加准确率信息\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    plt.text(0.5, -0.1, f'Accuracy: {accuracy:.4f}', \n",
    "             transform=plt.gca().transAxes, ha='center', fontweight='bold')\n",
    "    \n",
    "    save_path = os.path.join(save_dir, f'{save_name}_confusion_matrix.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Saved: {save_path}\")\n",
    "\n",
    "def plot_ensemble_analysis(models_dict, data_loader, device):\n",
    "    \"\"\"绘制集成分析可视化 - 修复版本\"\"\"\n",
    "    print(\"🔍 生成集成分析可视化...\")\n",
    "    \n",
    "    # 收集所有模型的预测结果\n",
    "    model_predictions = {}\n",
    "    true_labels = []\n",
    "    \n",
    "    # 初始化模型预测字典\n",
    "    for model_key in models_dict.keys():\n",
    "        model_predictions[model_key] = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(data_loader, desc=\"收集模型预测\"):\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # 收集真实标签\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # 收集每个模型的预测\n",
    "            for model_key, model in models_dict.items():\n",
    "                # AMP推理\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(imgs)\n",
    "                else:\n",
    "                    outputs = model(imgs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                model_predictions[model_key].extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # 转换为numpy数组\n",
    "    for key in model_predictions:\n",
    "        model_predictions[key] = np.array(model_predictions[key])\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    # 验证数组长度一致性\n",
    "    print(f\"📊 数据验证: 真实标签数量={len(true_labels)}\")\n",
    "    for key, preds in model_predictions.items():\n",
    "        print(f\"📊 {MODEL_CONFIGS[key]['name']} 预测数量={len(preds)}\")\n",
    "        if len(preds) != len(true_labels):\n",
    "            print(f\"⚠️ 警告: {MODEL_CONFIGS[key]['name']} 预测数量与真实标签不匹配!\")\n",
    "            return\n",
    "    \n",
    "    # 1. 模型预测一致性热图\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Ensemble Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 计算模型间一致性\n",
    "    model_keys = list(model_predictions.keys())\n",
    "    n_models = len(model_keys)\n",
    "    consistency_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, key1 in enumerate(model_keys):\n",
    "        for j, key2 in enumerate(model_keys):\n",
    "            if i == j:\n",
    "                consistency_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                agreement = np.mean(model_predictions[key1] == model_predictions[key2])\n",
    "                consistency_matrix[i, j] = agreement\n",
    "    \n",
    "    # 绘制一致性热图\n",
    "    model_names = [MODEL_CONFIGS[key]['name'] for key in model_keys]\n",
    "    sns.heatmap(consistency_matrix, annot=True, fmt='.3f', cmap='RdYlBu_r',\n",
    "                xticklabels=model_names, yticklabels=model_names, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Model Prediction Consistency', fontweight='bold')\n",
    "    \n",
    "    # 2. 各模型准确率对比\n",
    "    accuracies = []\n",
    "    for key in model_keys:\n",
    "        acc = accuracy_score(true_labels, model_predictions[key])\n",
    "        accuracies.append(acc)\n",
    "        print(f\"📊 {MODEL_CONFIGS[key]['name']} 准确率: {acc:.4f}\")\n",
    "    \n",
    "    bars = axes[0, 1].bar(model_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'][:len(model_names)])\n",
    "    axes[0, 1].set_title('Individual Model Accuracy', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                       f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. 集成预测置信度分析\n",
    "    print(\"🔍 计算集成预测置信度...\")\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(data_loader, desc=\"计算置信度\"):\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            batch_probs = []\n",
    "            \n",
    "            for model_key, model in models_dict.items():\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(imgs)\n",
    "                else:\n",
    "                    outputs = model(imgs)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                batch_probs.append(probs.cpu().numpy())\n",
    "            \n",
    "            # 平均概率\n",
    "            ensemble_probs = np.mean(batch_probs, axis=0)\n",
    "            all_probs.extend(ensemble_probs)\n",
    "    \n",
    "    all_probs = np.array(all_probs)\n",
    "    ensemble_confidence = np.max(all_probs, axis=1)\n",
    "    ensemble_predictions = np.argmax(all_probs, axis=1)\n",
    "    \n",
    "    # 正确vs错误预测的置信度分布\n",
    "    correct_mask = ensemble_predictions == true_labels\n",
    "    correct_confidence = ensemble_confidence[correct_mask]\n",
    "    incorrect_confidence = ensemble_confidence[~correct_mask]\n",
    "    \n",
    "    axes[1, 0].hist(correct_confidence, bins=30, alpha=0.7, label='Correct', color='green', density=True)\n",
    "    axes[1, 0].hist(incorrect_confidence, bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n",
    "    axes[1, 0].set_title('Prediction Confidence Distribution', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Confidence')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 4. 各类别F1-score对比\n",
    "    f1_scores = {}\n",
    "    for key in model_keys:\n",
    "        f1 = f1_score(true_labels, model_predictions[key], average=None)\n",
    "        f1_scores[key] = f1\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, (key, f1) in enumerate(f1_scores.items()):\n",
    "        offset = (i - len(model_keys)/2 + 0.5) * width\n",
    "        axes[1, 1].bar(x + offset, f1, width, label=MODEL_CONFIGS[key]['name'])\n",
    "    \n",
    "    axes[1, 1].set_title('F1-Score by Class', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Class')\n",
    "    axes[1, 1].set_ylabel('F1-Score')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(classes)\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(PLOTS_DIR, 'ensemble_analysis.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ 保存集成分析: {save_path}\")\n",
    "    \n",
    "    # 返回统计信息\n",
    "    return {\n",
    "        'model_accuracies': dict(zip(model_keys, accuracies)),\n",
    "        'ensemble_accuracy': accuracy_score(true_labels, ensemble_predictions),\n",
    "        'consistency_matrix': consistency_matrix,\n",
    "        'model_names': model_names\n",
    "    }\n",
    "    \n",
    "def plot_interpretability_analysis(models_dict, data_loader, device):\n",
    "    \"\"\"绘制模型解释性分析（如果Captum可用）- 修复版本\"\"\"\n",
    "    if not CAPTUM_AVAILABLE:\n",
    "        print(\"⚠️ Captum不可用，跳过解释性分析\")\n",
    "        return\n",
    "    \n",
    "    print(\"🔍 生成模型解释性分析...\")\n",
    "    \n",
    "    try:\n",
    "        # 获取一个批次的数据进行分析\n",
    "        data_iter = iter(data_loader)\n",
    "        imgs, labels = next(data_iter)\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        # 只分析前4张图片\n",
    "        sample_imgs = imgs[:4]\n",
    "        sample_labels = labels[:4]\n",
    "        \n",
    "        fig, axes = plt.subplots(len(models_dict), 4, figsize=(16, 4*len(models_dict)))\n",
    "        if len(models_dict) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for model_idx, (model_key, model) in enumerate(models_dict.items()):\n",
    "            print(f\"🔍 分析 {MODEL_CONFIGS[model_key]['name']} 的解释性...\")\n",
    "            \n",
    "            try:\n",
    "                # 创建一个包装器来处理多GPU模型\n",
    "                if hasattr(model, 'module'):\n",
    "                    # 如果是DataParallel模型，使用module\n",
    "                    analysis_model = model.module\n",
    "                else:\n",
    "                    analysis_model = model\n",
    "                \n",
    "                # 使用Integrated Gradients\n",
    "                ig = IntegratedGradients(analysis_model)\n",
    "                \n",
    "                for img_idx in range(4):\n",
    "                    try:\n",
    "                        single_img = sample_imgs[img_idx:img_idx+1]\n",
    "                        single_label = sample_labels[img_idx:img_idx+1]\n",
    "                        \n",
    "                        # 计算归因\n",
    "                        if USE_AMP:\n",
    "                            # 对于解释性分析，暂时不使用AMP以避免兼容性问题\n",
    "                            attributions = ig.attribute(single_img, target=single_label)\n",
    "                        else:\n",
    "                            attributions = ig.attribute(single_img, target=single_label)\n",
    "                        \n",
    "                        # 可视化\n",
    "                        attr_img = attributions.squeeze().cpu().detach().numpy()\n",
    "                        attr_img = np.transpose(attr_img, (1, 2, 0))\n",
    "                        \n",
    "                        # 归一化到0-1\n",
    "                        if attr_img.max() != attr_img.min():\n",
    "                            attr_img = (attr_img - attr_img.min()) / (attr_img.max() - attr_img.min())\n",
    "                        else:\n",
    "                            attr_img = np.zeros_like(attr_img)\n",
    "                        \n",
    "                        axes[model_idx, img_idx].imshow(attr_img)\n",
    "                        axes[model_idx, img_idx].set_title(f'{MODEL_CONFIGS[model_key][\"name\"]}\\nSample {img_idx+1}')\n",
    "                        axes[model_idx, img_idx].axis('off')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ 样本 {img_idx+1} 分析失败: {e}\")\n",
    "                        axes[model_idx, img_idx].text(0.5, 0.5, f'Sample {img_idx+1}\\nFailed', \n",
    "                                                    ha='center', va='center', transform=axes[model_idx, img_idx].transAxes)\n",
    "                        axes[model_idx, img_idx].set_title(f'{MODEL_CONFIGS[model_key][\"name\"]}\\nSample {img_idx+1}')\n",
    "                        axes[model_idx, img_idx].axis('off')\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {MODEL_CONFIGS[model_key]['name']} 整体解释性分析失败: {e}\")\n",
    "                for img_idx in range(4):\n",
    "                    axes[model_idx, img_idx].text(0.5, 0.5, 'Analysis\\nFailed', \n",
    "                                                ha='center', va='center', transform=axes[model_idx, img_idx].transAxes)\n",
    "                    axes[model_idx, img_idx].set_title(f'{MODEL_CONFIGS[model_key][\"name\"]}\\nSample {img_idx+1}')\n",
    "                    axes[model_idx, img_idx].axis('off')\n",
    "        \n",
    "        plt.suptitle('Model Interpretability Analysis (Integrated Gradients)', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(PLOTS_DIR, 'interpretability_analysis.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✅ 保存解释性分析: {save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 解释性分析完全失败: {e}\")\n",
    "        print(\"💡 建议: 检查Captum版本或尝试重新安装\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 8: 集成预测函数 (支持AMP)\n",
    "def ensemble_predict(models_dict, data_loader, voting_type='soft', weights=None):\n",
    "    \"\"\"集成预测函数 - 支持AMP混合精度\"\"\"\n",
    "    print(f\"🔮 开始集成预测 (投票方式: {voting_type})\")\n",
    "    if USE_AMP:\n",
    "        print(\"⚡ 使用AMP加速集成预测\")\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    model_outputs = {key: [] for key in models_dict.keys()}\n",
    "    \n",
    "    # 如果是加权投票但没有提供权重，则使用等权重\n",
    "    if voting_type == 'weighted' and weights is None:\n",
    "        weights = {key: 1.0 for key in models_dict.keys()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(data_loader, desc=\"集成预测\"):\n",
    "            imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
    "            \n",
    "            # 收集每个模型的预测\n",
    "            batch_predictions = []\n",
    "            for model_key, model in models_dict.items():\n",
    "                # AMP推理\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(imgs)\n",
    "                else:\n",
    "                    outputs = model(imgs)\n",
    "                \n",
    "                if voting_type in ['soft', 'weighted']:\n",
    "                    probs = torch.softmax(outputs, dim=1)\n",
    "                    batch_predictions.append(probs.cpu().numpy())\n",
    "                else:  # hard voting\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    batch_predictions.append(predicted.cpu().numpy())\n",
    "                \n",
    "                model_outputs[model_key].extend(outputs.cpu().numpy())\n",
    "            \n",
    "            # 集成预测\n",
    "            if voting_type == 'soft':\n",
    "                # 软投票：平均概率\n",
    "                ensemble_probs = np.mean(batch_predictions, axis=0)\n",
    "                ensemble_pred = np.argmax(ensemble_probs, axis=1)\n",
    "            elif voting_type == 'weighted':\n",
    "                # 加权投票：根据权重加权平均概率\n",
    "                weighted_probs = np.zeros_like(batch_predictions[0])\n",
    "                total_weight = 0\n",
    "                for i, (model_key, probs) in enumerate(zip(models_dict.keys(), batch_predictions)):\n",
    "                    weight = weights[model_key]\n",
    "                    weighted_probs += probs * weight\n",
    "                    total_weight += weight\n",
    "                ensemble_probs = weighted_probs / total_weight\n",
    "                ensemble_pred = np.argmax(ensemble_probs, axis=1)\n",
    "            else:\n",
    "                # 硬投票：多数投票\n",
    "                batch_predictions = np.array(batch_predictions)\n",
    "                ensemble_pred = []\n",
    "                for i in range(batch_predictions.shape[1]):\n",
    "                    votes = batch_predictions[:, i]\n",
    "                    ensemble_pred.append(np.bincount(votes).argmax())\n",
    "                ensemble_pred = np.array(ensemble_pred)\n",
    "            \n",
    "            all_predictions.extend(ensemble_pred)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels), model_outputs\n",
    "\n",
    "def calculate_model_weights(model_results, weight_method='accuracy'):\n",
    "    \"\"\"计算模型权重\"\"\"\n",
    "    weights = {}\n",
    "    \n",
    "    if weight_method == 'accuracy':\n",
    "        # 基于验证准确率计算权重\n",
    "        accuracies = {key: results['best_acc'] for key, results in model_results.items()}\n",
    "        total_acc = sum(accuracies.values())\n",
    "        \n",
    "        for key, acc in accuracies.items():\n",
    "            weights[key] = acc / total_acc\n",
    "            \n",
    "    elif weight_method == 'softmax':\n",
    "        # 使用softmax归一化准确率作为权重\n",
    "        accuracies = np.array([results['best_acc'] for results in model_results.values()])\n",
    "        softmax_weights = np.exp(accuracies * 10) / np.sum(np.exp(accuracies * 10))  # 乘以10增强差异\n",
    "        \n",
    "        for i, key in enumerate(model_results.keys()):\n",
    "            weights[key] = softmax_weights[i]\n",
    "            \n",
    "    elif weight_method == 'rank':\n",
    "        # 基于排名的权重分配\n",
    "        sorted_models = sorted(model_results.items(), key=lambda x: x[1]['best_acc'], reverse=True)\n",
    "        n_models = len(sorted_models)\n",
    "        \n",
    "        for i, (key, _) in enumerate(sorted_models):\n",
    "            weights[key] = (n_models - i) / sum(range(1, n_models + 1))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在Cell 8后添加新的Cell: 模型加载和辅助函数\n",
    "def load_trained_models(model_paths):\n",
    "    \"\"\"加载训练好的模型\"\"\"\n",
    "    print(\"📂 加载训练好的模型...\")\n",
    "    trained_models = {}\n",
    "    \n",
    "    for model_key, model_path in model_paths.items():\n",
    "        if os.path.exists(model_path):\n",
    "            # 创建模型架构\n",
    "            model = MODEL_CONFIGS[model_key]['create_fn']()\n",
    "            \n",
    "            # 加载权重\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "                model = model.to(DEVICE)\n",
    "                model.eval()  # 设置为评估模式\n",
    "                \n",
    "                # 多GPU支持\n",
    "                if NUM_GPUS > 1:\n",
    "                    model = nn.DataParallel(model)\n",
    "                \n",
    "                trained_models[model_key] = model\n",
    "                print(f\"✅ 成功加载 {MODEL_CONFIGS[model_key]['name']} 从 {model_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ 加载 {MODEL_CONFIGS[model_key]['name']} 失败: {e}\")\n",
    "        else:\n",
    "            print(f\"⚠️ 模型文件不存在: {model_path}\")\n",
    "    \n",
    "    print(f\"📊 成功加载 {len(trained_models)}/{len(model_paths)} 个模型\")\n",
    "    return trained_models\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, save_name):\n",
    "    \"\"\"绘制混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(f'{title} - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontweight='bold')\n",
    "    plt.ylabel('True Label', fontweight='bold')\n",
    "    \n",
    "    # 添加准确率信息\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    plt.figtext(0.02, 0.02, f'Accuracy: {accuracy:.4f}', fontsize=12, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\"))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(PLOTS_DIR, f'{save_name}_confusion_matrix.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ 保存混淆矩阵: {save_path}\")\n",
    "\n",
    "def plot_ensemble_analysis(models_dict, data_loader, device):\n",
    "    \"\"\"绘制集成分析可视化\"\"\"\n",
    "    print(\"🔍 生成集成分析可视化...\")\n",
    "    \n",
    "    # 收集所有模型的预测结果\n",
    "    model_predictions = {}\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(data_loader, desc=\"收集模型预测\"):\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            if len(true_labels) == 0:  # 只在第一次收集真实标签\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            for model_key, model in models_dict.items():\n",
    "                if model_key not in model_predictions:\n",
    "                    model_predictions[model_key] = []\n",
    "                \n",
    "                # AMP推理\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(imgs)\n",
    "                else:\n",
    "                    outputs = model(imgs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                model_predictions[model_key].extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # 转换为numpy数组\n",
    "    for key in model_predictions:\n",
    "        model_predictions[key] = np.array(model_predictions[key])\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    # 1. 模型预测一致性热图\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Ensemble Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 计算模型间一致性\n",
    "    model_keys = list(model_predictions.keys())\n",
    "    n_models = len(model_keys)\n",
    "    consistency_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, key1 in enumerate(model_keys):\n",
    "        for j, key2 in enumerate(model_keys):\n",
    "            if i == j:\n",
    "                consistency_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                agreement = np.mean(model_predictions[key1] == model_predictions[key2])\n",
    "                consistency_matrix[i, j] = agreement\n",
    "    \n",
    "    # 绘制一致性热图\n",
    "    model_names = [MODEL_CONFIGS[key]['name'] for key in model_keys]\n",
    "    sns.heatmap(consistency_matrix, annot=True, fmt='.3f', cmap='RdYlBu_r',\n",
    "                xticklabels=model_names, yticklabels=model_names, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Model Prediction Consistency', fontweight='bold')\n",
    "    \n",
    "    # 2. 各模型准确率对比\n",
    "    accuracies = []\n",
    "    for key in model_keys:\n",
    "        acc = accuracy_score(true_labels, model_predictions[key])\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    bars = axes[0, 1].bar(model_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'][:len(model_names)])\n",
    "    axes[0, 1].set_title('Individual Model Accuracy', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                       f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. 集成预测置信度分析\n",
    "    # 计算软投票结果\n",
    "    all_probs = []\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        batch_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model_key, model in models_dict.items():\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(imgs)\n",
    "                else:\n",
    "                    outputs = model(imgs)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                batch_probs.append(probs.cpu().numpy())\n",
    "        \n",
    "        # 平均概率\n",
    "        ensemble_probs = np.mean(batch_probs, axis=0)\n",
    "        all_probs.extend(ensemble_probs)\n",
    "    \n",
    "    all_probs = np.array(all_probs)\n",
    "    ensemble_confidence = np.max(all_probs, axis=1)\n",
    "    ensemble_predictions = np.argmax(all_probs, axis=1)\n",
    "    \n",
    "    # 正确vs错误预测的置信度分布\n",
    "    correct_mask = ensemble_predictions == true_labels\n",
    "    correct_confidence = ensemble_confidence[correct_mask]\n",
    "    incorrect_confidence = ensemble_confidence[~correct_mask]\n",
    "    \n",
    "    axes[1, 0].hist(correct_confidence, bins=30, alpha=0.7, label='Correct', color='green', density=True)\n",
    "    axes[1, 0].hist(incorrect_confidence, bins=30, alpha=0.7, label='Incorrect', color='red', density=True)\n",
    "    axes[1, 0].set_title('Prediction Confidence Distribution', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Confidence')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # 4. 各类别F1-score对比\n",
    "    f1_scores = {}\n",
    "    for key in model_keys:\n",
    "        f1 = f1_score(true_labels, model_predictions[key], average=None)\n",
    "        f1_scores[key] = f1\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, (key, f1) in enumerate(f1_scores.items()):\n",
    "        offset = (i - len(model_keys)/2 + 0.5) * width\n",
    "        axes[1, 1].bar(x + offset, f1, width, label=MODEL_CONFIGS[key]['name'])\n",
    "    \n",
    "    axes[1, 1].set_title('F1-Score by Class', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Class')\n",
    "    axes[1, 1].set_ylabel('F1-Score')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(classes)\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(PLOTS_DIR, 'ensemble_analysis.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ 保存集成分析: {save_path}\")\n",
    "\n",
    "def plot_interpretability_analysis(models_dict, data_loader, device):\n",
    "    \"\"\"绘制模型解释性分析（如果Captum可用）\"\"\"\n",
    "    if not CAPTUM_AVAILABLE:\n",
    "        print(\"⚠️ Captum不可用，跳过解释性分析\")\n",
    "        return\n",
    "    \n",
    "    print(\"🔍 生成模型解释性分析...\")\n",
    "    \n",
    "    # 获取一个批次的数据进行分析\n",
    "    data_iter = iter(data_loader)\n",
    "    imgs, labels = next(data_iter)\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    \n",
    "    # 只分析前4张图片\n",
    "    sample_imgs = imgs[:4]\n",
    "    sample_labels = labels[:4]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(models_dict), 4, figsize=(16, 4*len(models_dict)))\n",
    "    if len(models_dict) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for model_idx, (model_key, model) in enumerate(models_dict.items()):\n",
    "        try:\n",
    "            # 使用Integrated Gradients\n",
    "            ig = IntegratedGradients(model)\n",
    "            \n",
    "            for img_idx in range(4):\n",
    "                single_img = sample_imgs[img_idx:img_idx+1]\n",
    "                single_label = sample_labels[img_idx:img_idx+1]\n",
    "                \n",
    "                # 计算归因\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        attributions = ig.attribute(single_img, target=single_label)\n",
    "                else:\n",
    "                    attributions = ig.attribute(single_img, target=single_label)\n",
    "                \n",
    "                # 可视化\n",
    "                attr_img = attributions.squeeze().cpu().detach().numpy()\n",
    "                attr_img = np.transpose(attr_img, (1, 2, 0))\n",
    "                \n",
    "                # 归一化到0-1\n",
    "                attr_img = (attr_img - attr_img.min()) / (attr_img.max() - attr_img.min())\n",
    "                \n",
    "                axes[model_idx, img_idx].imshow(attr_img)\n",
    "                axes[model_idx, img_idx].set_title(f'{MODEL_CONFIGS[model_key][\"name\"]}\\nSample {img_idx+1}')\n",
    "                axes[model_idx, img_idx].axis('off')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {MODEL_CONFIGS[model_key]['name']} 解释性分析失败: {e}\")\n",
    "            for img_idx in range(4):\n",
    "                axes[model_idx, img_idx].text(0.5, 0.5, 'Analysis\\nFailed', \n",
    "                                            ha='center', va='center', transform=axes[model_idx, img_idx].transAxes)\n",
    "                axes[model_idx, img_idx].set_title(f'{MODEL_CONFIGS[model_key][\"name\"]}\\nSample {img_idx+1}')\n",
    "    \n",
    "    plt.suptitle('Model Interpretability Analysis (Integrated Gradients)', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(PLOTS_DIR, 'interpretability_analysis.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ 保存解释性分析: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 加载数据集...\n",
      "训练集图片数: 140002\n",
      "训练集类别分布:\n",
      "  Real: 70001 (50.0%)\n",
      "  Fake: 70001 (50.0%)\n",
      "验证集图片数: 39428\n",
      "验证集类别分布:\n",
      "  Real: 19787 (50.2%)\n",
      "  Fake: 19641 (49.8%)\n",
      "⚠️ 验证集过大 (39428 张)，随机采样 12800 张图片\n",
      "✅ 验证集采样完成，当前大小: 12800\n",
      "验证集类别分布:\n",
      "  Real: 6400 (50.0%)\n",
      "  Fake: 6400 (50.0%)\n",
      "\n",
      "📊 数据集总览:\n",
      "训练集总数: 140002\n",
      "验证集总数: 12800\n",
      "验证批次数: 400\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: 加载数据\n",
    "print(\"📂 加载数据集...\")\n",
    "train_df = create_dataframe(TRAIN_PATH, \"训练\")\n",
    "val_df = create_dataframe(VAL_PATH, \"验证\")\n",
    "\n",
    "# 限制验证集大小为6400以减少内存使用\n",
    "MAX_VAL_SAMPLES = 12800\n",
    "if len(val_df) > MAX_VAL_SAMPLES:\n",
    "    print(f\"⚠️ 验证集过大 ({len(val_df)} 张)，随机采样 {MAX_VAL_SAMPLES} 张图片\")\n",
    "    # 保持类别平衡的随机采样\n",
    "    val_df = val_df.groupby('label', group_keys=False).apply(\n",
    "        lambda x: x.sample(min(len(x), MAX_VAL_SAMPLES//2), random_state=42)\n",
    "    ).reset_index(drop=True)\n",
    "    print(f\"✅ 验证集采样完成，当前大小: {len(val_df)}\")\n",
    "    print(f\"验证集类别分布:\")\n",
    "    for idx, cls in enumerate(classes):\n",
    "        count = len(val_df[val_df['label'] == idx])\n",
    "        print(f\"  {cls}: {count} ({count/len(val_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n📊 数据集总览:\")\n",
    "print(f\"训练集总数: {len(train_df)}\")\n",
    "print(f\"验证集总数: {len(val_df)}\")\n",
    "print(f\"验证批次数: {len(val_df) // BATCH_SIZE + (1 if len(val_df) % BATCH_SIZE > 0 else 0)}\")\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_dataset = DeepfakeDataset(train_df, transform=train_transform)\n",
    "val_dataset = DeepfakeDataset(val_df, transform=val_transform)\n",
    "\n",
    "# 使用动态配置的num_workers和pin_memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 开始训练多个模型...\n",
      "\n",
      "🔥 Starting Training EfficientNet-B0\n",
      "⚡ Using AMP (Automatic Mixed Precision) for faster training\n",
      "🔍 Initial GPU Memory: 0.02GB / 0.02GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 4376/4376 [18:03<00:00,  4.04it/s]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 400/400 [00:34<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0794, Val Loss: 0.0785, Val Acc: 0.9720, Val F1: 0.9720, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Train]: 100%|██████████| 4376/4376 [15:39<00:00,  4.66it/s]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 400/400 [00:20<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0444, Val Loss: 0.0575, Val Acc: 0.9798, Val F1: 0.9798, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Train]: 100%|██████████| 4376/4376 [15:41<00:00,  4.65it/s]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 400/400 [00:21<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0365, Val Loss: 0.0507, Val Acc: 0.9809, Val F1: 0.9809, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Train]: 100%|██████████| 4376/4376 [15:35<00:00,  4.68it/s]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 400/400 [00:20<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0336, Val Loss: 0.0632, Val Acc: 0.9778, Val F1: 0.9778, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Train]: 100%|██████████| 4376/4376 [15:42<00:00,  4.64it/s]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 400/400 [00:21<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0323, Val Loss: 0.0488, Val Acc: 0.9822, Val F1: 0.9822, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 [Train]: 100%|██████████| 4376/4376 [15:31<00:00,  4.70it/s]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 400/400 [00:20<00:00, 19.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0307, Val Loss: 0.0417, Val Acc: 0.9862, Val F1: 0.9862, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 [Train]: 100%|██████████| 4376/4376 [15:30<00:00,  4.70it/s]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 400/400 [00:20<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0293, Val Loss: 0.0527, Val Acc: 0.9809, Val F1: 0.9809, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 [Train]: 100%|██████████| 4376/4376 [15:35<00:00,  4.68it/s]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 400/400 [00:20<00:00, 19.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0290, Val Loss: 0.0382, Val Acc: 0.9869, Val F1: 0.9869, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 [Train]: 100%|██████████| 4376/4376 [15:45<00:00,  4.63it/s]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 400/400 [00:21<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0277, Val Loss: 0.0514, Val Acc: 0.9835, Val F1: 0.9835, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 [Train]: 100%|██████████| 4376/4376 [15:44<00:00,  4.64it/s]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 400/400 [00:20<00:00, 19.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0274, Val Loss: 0.0526, Val Acc: 0.9816, Val F1: 0.9816, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 [Train]: 100%|██████████| 4376/4376 [15:41<00:00,  4.65it/s]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 400/400 [00:20<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0279, Val Loss: 0.0375, Val Acc: 0.9863, Val F1: 0.9863, LR: 0.000100 GPU Mem: 0.10GB/1.84GB\n",
      "⛔ Early stopping triggered\n",
      "⏱️ Training completed in 10715.97 seconds\n",
      "🧹 Final GPU Memory: 0.10GB\n",
      "✅ EfficientNet-B0 训练完成，最佳验证准确率: 0.9869\n",
      "\n",
      "🔥 Starting Training ResNet18\n",
      "⚡ Using AMP (Automatic Mixed Precision) for faster training\n",
      "🔍 Initial GPU Memory: 0.06GB / 1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 4376/4376 [13:36<00:00,  5.36it/s]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0784, Val Loss: 0.0955, Val Acc: 0.9673, Val F1: 0.9673, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Train]: 100%|██████████| 4376/4376 [13:39<00:00,  5.34it/s]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 400/400 [00:19<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0500, Val Loss: 0.0900, Val Acc: 0.9710, Val F1: 0.9710, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Train]: 100%|██████████| 4376/4376 [13:42<00:00,  5.32it/s]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0436, Val Loss: 0.0779, Val Acc: 0.9727, Val F1: 0.9727, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Train]: 100%|██████████| 4376/4376 [13:38<00:00,  5.34it/s]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0408, Val Loss: 0.0614, Val Acc: 0.9780, Val F1: 0.9780, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Train]: 100%|██████████| 4376/4376 [13:36<00:00,  5.36it/s]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0381, Val Loss: 0.0532, Val Acc: 0.9832, Val F1: 0.9832, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 [Train]: 100%|██████████| 4376/4376 [13:36<00:00,  5.36it/s]\n",
      "Epoch 6/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.0362, Val Loss: 0.0674, Val Acc: 0.9780, Val F1: 0.9780, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 [Train]: 100%|██████████| 4376/4376 [13:37<00:00,  5.36it/s]\n",
      "Epoch 7/15 [Val]: 100%|██████████| 400/400 [00:19<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.0338, Val Loss: 0.0550, Val Acc: 0.9812, Val F1: 0.9812, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 [Train]: 100%|██████████| 4376/4376 [13:39<00:00,  5.34it/s]\n",
      "Epoch 8/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.0327, Val Loss: 0.0493, Val Acc: 0.9833, Val F1: 0.9833, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 [Train]: 100%|██████████| 4376/4376 [13:24<00:00,  5.44it/s]\n",
      "Epoch 9/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.0314, Val Loss: 0.0466, Val Acc: 0.9844, Val F1: 0.9844, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "✅ Best model saved, validation accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 [Train]: 100%|██████████| 4376/4376 [13:29<00:00,  5.41it/s]\n",
      "Epoch 10/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.0305, Val Loss: 0.0490, Val Acc: 0.9818, Val F1: 0.9818, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 [Train]: 100%|██████████| 4376/4376 [13:28<00:00,  5.41it/s]\n",
      "Epoch 11/15 [Val]: 100%|██████████| 400/400 [00:18<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.0295, Val Loss: 0.0671, Val Acc: 0.9770, Val F1: 0.9770, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 [Train]: 100%|██████████| 4376/4376 [13:30<00:00,  5.40it/s]\n",
      "Epoch 12/15 [Val]: 100%|██████████| 400/400 [00:19<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.0287, Val Loss: 0.0530, Val Acc: 0.9814, Val F1: 0.9814, LR: 0.000100 GPU Mem: 0.21GB/1.84GB\n",
      "⛔ Early stopping triggered\n",
      "⏱️ Training completed in 10005.60 seconds\n",
      "🧹 Final GPU Memory: 0.21GB\n",
      "✅ ResNet18 训练完成，最佳验证准确率: 0.9844\n",
      "\n",
      "🔥 Starting Training ConvNeXt-Tiny\n",
      "⚡ Using AMP (Automatic Mixed Precision) for faster training\n",
      "🔍 Initial GPU Memory: 0.12GB / 1.84GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 4376/4376 [20:20<00:00,  3.59it/s]\n",
      "Epoch 1/15 [Val]: 100%|██████████| 400/400 [00:30<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0696, Val Loss: 0.0718, Val Acc: 0.9726, Val F1: 0.9726, LR: 0.000100 GPU Mem: 0.47GB/2.81GB\n",
      "✅ Best model saved, validation accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Train]: 100%|██████████| 4376/4376 [20:23<00:00,  3.58it/s]\n",
      "Epoch 2/15 [Val]: 100%|██████████| 400/400 [00:30<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0463, Val Loss: 0.0520, Val Acc: 0.9812, Val F1: 0.9812, LR: 0.000100 GPU Mem: 0.47GB/2.81GB\n",
      "✅ Best model saved, validation accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 [Train]: 100%|██████████| 4376/4376 [20:26<00:00,  3.57it/s]\n",
      "Epoch 3/15 [Val]: 100%|██████████| 400/400 [00:31<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0427, Val Loss: 0.0733, Val Acc: 0.9752, Val F1: 0.9752, LR: 0.000100 GPU Mem: 0.47GB/2.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 [Train]: 100%|██████████| 4376/4376 [20:13<00:00,  3.61it/s]\n",
      "Epoch 4/15 [Val]: 100%|██████████| 400/400 [00:30<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0410, Val Loss: 0.0940, Val Acc: 0.9661, Val F1: 0.9661, LR: 0.000100 GPU Mem: 0.47GB/2.81GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 [Train]: 100%|██████████| 4376/4376 [20:30<00:00,  3.56it/s]\n",
      "Epoch 5/15 [Val]: 100%|██████████| 400/400 [00:30<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.0385, Val Loss: 0.0668, Val Acc: 0.9752, Val F1: 0.9752, LR: 0.000100 GPU Mem: 0.47GB/2.81GB\n",
      "⛔ Early stopping triggered\n",
      "⏱️ Training completed in 6268.30 seconds\n",
      "🧹 Final GPU Memory: 0.47GB\n",
      "✅ ConvNeXt-Tiny 训练完成，最佳验证准确率: 0.9812\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: 训练所有模型\n",
    "print(\"\\n🚀 开始训练多个模型...\")\n",
    "\n",
    "# 选择要训练的模型（可以根据需要调整）\n",
    "selected_models = ['efficientnet_b0', 'resnet18', 'convnext_tiny']  # 减少模型数量以适应Kaggle环境\n",
    "model_paths = {}\n",
    "model_results = {}\n",
    "\n",
    "for model_key in selected_models:\n",
    "    save_path = f\"best_{model_key}_model.pth\"\n",
    "    model_paths[model_key] = save_path\n",
    "    \n",
    "    # 使用新的训练函数返回格式\n",
    "    model_results[model_key] = train_single_model(\n",
    "        model_key, train_loader, val_loader, save_path\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ {MODEL_CONFIGS[model_key]['name']} 训练完成，最佳验证准确率: {model_results[model_key]['best_acc']:.4f}\")\n",
    "    \n",
    "    # 清理GPU内存\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 生成训练历史可视化...\n",
      "📊 Generating training history visualizations...\n",
      "✅ Saved: ./works/plots\\efficientnet_b0_training_history.png\n",
      "✅ Saved: ./works/plots\\resnet18_training_history.png\n",
      "✅ Saved: ./works/plots\\convnext_tiny_training_history.png\n",
      "✅ Saved: ./works/plots\\multi_model_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: 增强训练历史可视化\n",
    "print(\"\\n📊 生成训练历史可视化...\")\n",
    "plot_training_history(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔮 开始集成预测...\n",
      "📂 加载训练好的模型...\n",
      "✅ 成功加载 EfficientNet-B0 从 best_efficientnet_b0_model.pth\n",
      "✅ 成功加载 ResNet18 从 best_resnet18_model.pth\n",
      "✅ 成功加载 ConvNeXt-Tiny 从 best_convnext_tiny_model.pth\n",
      "📊 成功加载 3/3 个模型\n",
      "\n",
      "⚖️ 计算模型权重...\n",
      "模型权重分配:\n",
      "  EfficientNet-B0: 0.3343\n",
      "  ResNet18       : 0.3334\n",
      "  ConvNeXt-Tiny  : 0.3323\n",
      "\n",
      "📊 软投票集成预测:\n",
      "🔮 开始集成预测 (投票方式: soft)\n",
      "⚡ 使用AMP加速集成预测\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "集成预测: 100%|██████████| 400/400 [00:44<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "软投票准确率: 0.9894\n",
      "\n",
      "📊 硬投票集成预测:\n",
      "🔮 开始集成预测 (投票方式: hard)\n",
      "⚡ 使用AMP加速集成预测\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "集成预测: 100%|██████████| 400/400 [00:43<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "硬投票准确率: 0.9889\n",
      "\n",
      "📊 加权投票集成预测:\n",
      "🔮 开始集成预测 (投票方式: weighted)\n",
      "⚡ 使用AMP加速集成预测\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "集成预测: 100%|██████████| 400/400 [00:43<00:00,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加权投票准确率: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: 集成预测和评估\n",
    "print(\"\\n🔮 开始集成预测...\")\n",
    "\n",
    "# 加载训练好的模型\n",
    "trained_models = load_trained_models(model_paths)\n",
    "\n",
    "# 计算模型权重\n",
    "print(\"\\n⚖️ 计算模型权重...\")\n",
    "model_weights = calculate_model_weights(model_results, weight_method='accuracy')\n",
    "print(\"模型权重分配:\")\n",
    "for model_key, weight in model_weights.items():\n",
    "    print(f\"  {MODEL_CONFIGS[model_key]['name']:15}: {weight:.4f}\")\n",
    "\n",
    "# 软投票预测\n",
    "print(\"\\n📊 软投票集成预测:\")\n",
    "soft_predictions, true_labels, _ = ensemble_predict(trained_models, val_loader, voting_type='soft')\n",
    "soft_accuracy = accuracy_score(true_labels, soft_predictions)\n",
    "print(f\"软投票准确率: {soft_accuracy:.4f}\")\n",
    "\n",
    "# 硬投票预测\n",
    "print(\"\\n📊 硬投票集成预测:\")\n",
    "hard_predictions, _, _ = ensemble_predict(trained_models, val_loader, voting_type='hard')\n",
    "hard_accuracy = accuracy_score(true_labels, hard_predictions)\n",
    "print(f\"硬投票准确率: {hard_accuracy:.4f}\")\n",
    "\n",
    "# 加权投票预测\n",
    "print(\"\\n📊 加权投票集成预测:\")\n",
    "weighted_predictions, _, _ = ensemble_predict(trained_models, val_loader, voting_type='weighted', weights=model_weights)\n",
    "weighted_accuracy = accuracy_score(true_labels, weighted_predictions)\n",
    "print(f\"加权投票准确率: {weighted_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 模型性能对比:\n",
      "==================================================\n",
      "EfficientNet-B0: 0.9869\n",
      "ResNet18       : 0.9844\n",
      "ConvNeXt-Tiny  : 0.9812\n",
      "软投票集成          : 0.9894\n",
      "硬投票集成          : 0.9889\n",
      "加权投票集成         : 0.9894\n",
      "\n",
      "📊 生成混淆矩阵可视化...\n",
      "✅ 保存混淆矩阵: ./works/plots\\soft_voting_confusion_matrix.png\n",
      "✅ 保存混淆矩阵: ./works/plots\\hard_voting_confusion_matrix.png\n",
      "✅ 保存混淆矩阵: ./works/plots\\weighted_voting_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: 结果对比和可视化\n",
    "# 单模型结果对比\n",
    "print(\"\\n📈 模型性能对比:\")\n",
    "print(\"=\"*50)\n",
    "for model_key in selected_models:\n",
    "    best_acc = model_results[model_key]['best_acc']\n",
    "    print(f\"{MODEL_CONFIGS[model_key]['name']:15}: {best_acc:.4f}\")\n",
    "\n",
    "print(f\"{'软投票集成':15}: {soft_accuracy:.4f}\")\n",
    "print(f\"{'硬投票集成':15}: {hard_accuracy:.4f}\")\n",
    "print(f\"{'加权投票集成':15}: {weighted_accuracy:.4f}\")\n",
    "\n",
    "# 增强混淆矩阵可视化\n",
    "print(\"\\n📊 生成混淆矩阵可视化...\")\n",
    "plot_confusion_matrix(true_labels, soft_predictions, \"Soft Voting Ensemble\", \"soft_voting\")\n",
    "plot_confusion_matrix(true_labels, hard_predictions, \"Hard Voting Ensemble\", \"hard_voting\")\n",
    "plot_confusion_matrix(true_labels, weighted_predictions, \"Weighted Voting Ensemble\", \"weighted_voting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 软投票详细分类报告:\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.99      0.99      0.99      6400\n",
      "        Fake       0.99      0.99      0.99      6400\n",
      "\n",
      "    accuracy                           0.99     12800\n",
      "   macro avg       0.99      0.99      0.99     12800\n",
      "weighted avg       0.99      0.99      0.99     12800\n",
      "\n",
      "\n",
      "📋 硬投票详细分类报告:\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.99      0.99      0.99      6400\n",
      "        Fake       0.99      0.99      0.99      6400\n",
      "\n",
      "    accuracy                           0.99     12800\n",
      "   macro avg       0.99      0.99      0.99     12800\n",
      "weighted avg       0.99      0.99      0.99     12800\n",
      "\n",
      "\n",
      "📋 加权投票详细分类报告:\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.99      0.99      0.99      6400\n",
      "        Fake       0.99      0.99      0.99      6400\n",
      "\n",
      "    accuracy                           0.99     12800\n",
      "   macro avg       0.99      0.99      0.99     12800\n",
      "weighted avg       0.99      0.99      0.99     12800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: 详细分类报告\n",
    "print(\"\\n📋 软投票详细分类报告:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(true_labels, soft_predictions, target_names=classes))\n",
    "\n",
    "print(\"\\n📋 硬投票详细分类报告:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(true_labels, hard_predictions, target_names=classes))\n",
    "\n",
    "print(\"\\n📋 加权投票详细分类报告:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(true_labels, weighted_predictions, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 生成集成分析可视化...\n",
      "🔍 生成集成分析可视化...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "收集模型预测: 100%|██████████| 400/400 [00:42<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 数据验证: 真实标签数量=12800\n",
      "📊 EfficientNet-B0 预测数量=12800\n",
      "📊 ResNet18 预测数量=12800\n",
      "📊 ConvNeXt-Tiny 预测数量=12800\n",
      "📊 EfficientNet-B0 准确率: 0.9869\n",
      "📊 ResNet18 准确率: 0.9844\n",
      "📊 ConvNeXt-Tiny 准确率: 0.9812\n",
      "🔍 计算集成预测置信度...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算置信度: 100%|██████████| 400/400 [00:43<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存集成分析: ./works/plots\\ensemble_analysis.png\n",
      "\n",
      "📊 生成模型解释性分析...\n",
      "🔍 生成模型解释性分析...\n",
      "🔍 分析 EfficientNet-B0 的解释性...\n",
      "🔍 分析 ResNet18 的解释性...\n",
      "🔍 分析 ConvNeXt-Tiny 的解释性...\n",
      "✅ 保存解释性分析: ./works/plots\\interpretability_analysis.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: 集成分析和解释性可视化\n",
    "print(\"\\n📊 生成集成分析可视化...\")\n",
    "plot_ensemble_analysis(trained_models, val_loader, DEVICE)\n",
    "\n",
    "print(\"\\n📊 生成模型解释性分析...\")\n",
    "plot_interpretability_analysis(trained_models, val_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎉 多模型集成训练完成！\n",
      "============================================================\n",
      "训练的模型数量: 3\n",
      "最佳单模型准确率: 0.9869\n",
      "软投票集成准确率: 0.9894\n",
      "硬投票集成准确率: 0.9889\n",
      "加权投票集成准确率: 0.9894\n",
      "软投票相对提升: +0.25%\n",
      "硬投票相对提升: +0.20%\n",
      "加权投票相对提升: +0.25%\n",
      "\n",
      "🏆 最佳集成方法: 软投票 (准确率: 0.9894)\n",
      "\n",
      "💾 保存的模型文件:\n",
      "  EfficientNet-B0: best_efficientnet_b0_model.pth\n",
      "  ResNet18: best_resnet18_model.pth\n",
      "  ConvNeXt-Tiny: best_convnext_tiny_model.pth\n",
      "\n",
      "⚖️ 模型权重分配:\n",
      "  EfficientNet-B0: 0.3343\n",
      "  ResNet18: 0.3334\n",
      "  ConvNeXt-Tiny: 0.3323\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: 最终总结\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 多模型集成训练完成！\")\n",
    "print(\"=\"*60)\n",
    "print(f\"训练的模型数量: {len(selected_models)}\")\n",
    "print(f\"最佳单模型准确率: {max([results['best_acc'] for results in model_results.values()]):.4f}\")\n",
    "print(f\"软投票集成准确率: {soft_accuracy:.4f}\")\n",
    "print(f\"硬投票集成准确率: {hard_accuracy:.4f}\")\n",
    "print(f\"加权投票集成准确率: {weighted_accuracy:.4f}\")\n",
    "\n",
    "# 计算提升幅度\n",
    "best_single = max([results['best_acc'] for results in model_results.values()])\n",
    "soft_improvement = (soft_accuracy - best_single) * 100\n",
    "hard_improvement = (hard_accuracy - best_single) * 100\n",
    "weighted_improvement = (weighted_accuracy - best_single) * 100\n",
    "\n",
    "print(f\"软投票相对提升: {soft_improvement:+.2f}%\")\n",
    "print(f\"硬投票相对提升: {hard_improvement:+.2f}%\")\n",
    "print(f\"加权投票相对提升: {weighted_improvement:+.2f}%\")\n",
    "\n",
    "# 找出最佳集成方法\n",
    "ensemble_results = {\n",
    "    '软投票': soft_accuracy,\n",
    "    '硬投票': hard_accuracy,\n",
    "    '加权投票': weighted_accuracy\n",
    "}\n",
    "best_ensemble = max(ensemble_results, key=ensemble_results.get)\n",
    "print(f\"\\n🏆 最佳集成方法: {best_ensemble} (准确率: {ensemble_results[best_ensemble]:.4f})\")\n",
    "\n",
    "print(f\"\\n💾 保存的模型文件:\")\n",
    "for model_key, path in model_paths.items():\n",
    "    print(f\"  {MODEL_CONFIGS[model_key]['name']}: {path}\")\n",
    "\n",
    "print(f\"\\n⚖️ 模型权重分配:\")\n",
    "for model_key, weight in model_weights.items():\n",
    "    print(f\"  {MODEL_CONFIGS[model_key]['name']}: {weight:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1909705,
     "sourceId": 3134515,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
