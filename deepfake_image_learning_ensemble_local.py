# =====================
# æ·±åº¦ä¼ªé€ å›¾åƒæ£€æµ‹ - å¤šæ¨¡å‹é›†æˆæŠ•ç¥¨ç‰ˆæœ¬ (æœ¬åœ°ä¼˜åŒ–ç‰ˆ)
# é’ˆå¯¹ 8GB RTX 4070 Laptop ä¼˜åŒ–
# =====================

# Cell 1: å¯¼å…¥ä¾èµ–å’Œç¯å¢ƒè®¾ç½®
import os
import cv2
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import warnings
import gc
import time
warnings.filterwarnings('ignore')

# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)

# é¿å…é‡å¤åˆå§‹åŒ–è¾“å‡º
if not hasattr(torch, '_deepfake_initialized'):
    print("ğŸš€ æœ¬åœ°å¤šæ¨¡å‹é›†æˆæ·±åº¦ä¼ªé€ æ£€æµ‹ (8GB RTX 4070 Laptop ä¼˜åŒ–ç‰ˆ)")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    torch._deepfake_initialized = True

# Cell 2: å‚æ•°é…ç½® (æœ¬åœ°ä¼˜åŒ–)
# æœ¬åœ°æ•°æ®è·¯å¾„ - è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
BASE_PATH = r'E:\program\deepfake_image\Dataset'  # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®é›†è·¯å¾„
TRAIN_PATH = os.path.join(BASE_PATH, 'Train')
VAL_PATH = os.path.join(BASE_PATH, 'Validation')

# è®­ç»ƒå‚æ•° (é’ˆå¯¹8GBæ˜¾å­˜ä¼˜åŒ– - æå‡GPUåˆ©ç”¨ç‡)
# é«˜GPUåˆ©ç”¨ç‡æ¨¡å¼ - å¦‚æœæ˜¾å­˜ä¸è¶³å¯ä»¥é™ä½è¿™äº›å‚æ•°
HIGH_GPU_UTILIZATION = True  # è®¾ç½®ä¸ºFalseå¯é™ä½æ˜¾å­˜ä½¿ç”¨


IMG_SIZE = 256 
BATCH_SIZE = 28  
LEARNING_RATE = 1e-4
EPOCHS = 15
WEIGHT_DECAY = 1e-4
PATIENCE = 4  # ä½¿ç”¨åŸç‰ˆæ—©åœè€å¿ƒ
NUM_WORKERS = 4

# GPUè®¾ç½®
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åªåœ¨ç¬¬ä¸€æ¬¡åˆå§‹åŒ–æ—¶è¾“å‡ºGPUä¿¡æ¯
if not hasattr(torch, '_deepfake_gpu_info_shown'):
    print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        # è®¾ç½®æ˜¾å­˜ä¼˜åŒ–
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        USE_AMP = True
        print("âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒä»¥èŠ‚çœæ˜¾å­˜")
    else:
        USE_AMP = False
        print("ä½¿ç”¨CPUè®­ç»ƒ")
    
    torch._deepfake_gpu_info_shown = True
else:
    # é™é»˜è®¾ç½®GPUå‚æ•°
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        USE_AMP = True
    else:
        USE_AMP = False



# Cell 3: æ•°æ®åŠ è½½å‡½æ•°
classes = ['Real', 'Fake']

def create_dataframe(data_path, dataset_type):
    """åˆ›å»ºæ•°æ®é›†DataFrame"""
    filepaths, labels = [], []
    
    for label_idx, cls in enumerate(classes):
        folder = os.path.join(data_path, cls)
        if os.path.exists(folder):
            for img_name in os.listdir(folder):
                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    filepaths.append(os.path.join(folder, img_name))
                    labels.append(label_idx)
    
    df = pd.DataFrame({'filepath': filepaths, 'label': labels})
    print(f"{dataset_type}é›†å›¾ç‰‡æ•°: {len(df)}")
    if len(df) > 0:
        print(f"{dataset_type}é›†ç±»åˆ«åˆ†å¸ƒ:")
        for idx, cls in enumerate(classes):
            count = len(df[df['label'] == idx])
            print(f"  {cls}: {count} ({count/len(df)*100:.1f}%)")
    return df

# Cell 4: æ•°æ®é¢„å¤„ç†å’Œå¢å¼º (è½»é‡åŒ–)
train_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=5),  # å‡å°‘æ—‹è½¬è§’åº¦
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # å‡å°‘å¢å¼ºå¼ºåº¦
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

class DeepfakeDataset(Dataset):
    def __init__(self, df, transform=None):
        self.df = df
        self.transform = transform
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        img_path = self.df.iloc[idx]['filepath']
        img = cv2.imread(img_path)
        if img is None:
            # å¦‚æœå›¾ç‰‡è¯»å–å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤å›¾ç‰‡
            img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        if self.transform:
            img = self.transform(img)
        
        label = self.df.iloc[idx]['label']
        return img, label

# Cell 5: æ¨¡å‹å®šä¹‰ (ä½¿ç”¨åŸç‰ˆæ¨¡å‹)
def create_efficientnet_b0():
    """åˆ›å»ºEfficientNet-B0æ¨¡å‹"""
    model = models.efficientnet_b0(weights='IMAGENET1K_V1')
    model.classifier[1] = nn.Linear(1280, 2)
    return model

def create_resnet18():
    """åˆ›å»ºResNet18æ¨¡å‹"""
    model = models.resnet18(weights='IMAGENET1K_V1')
    model.fc = nn.Linear(512, 2)
    return model

def create_convnext_tiny():
    """åˆ›å»ºConvNeXt-Tinyæ¨¡å‹"""
    model = models.convnext_tiny(weights='IMAGENET1K_V1')
    model.classifier[2] = nn.Linear(768, 2)
    return model

# æ¨¡å‹é…ç½®å­—å…¸ (ä½¿ç”¨åŸç‰ˆæ¨¡å‹)
MODEL_CONFIGS = {
    'efficientnet_b0': {
        'create_fn': create_efficientnet_b0,
        'name': 'EfficientNet-B0'
    },
    'resnet18': {
        'create_fn': create_resnet18,
        'name': 'ResNet18'
    },
    'convnext_tiny': {
        'create_fn': create_convnext_tiny,
        'name': 'ConvNeXt-Tiny'
    }
}

# Cell 6: ä¼˜åŒ–çš„å•æ¨¡å‹è®­ç»ƒå‡½æ•°
def train_single_model(model_key, train_loader, val_loader, save_path):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹ (æ˜¾å­˜ä¼˜åŒ–ç‰ˆ)"""
    print(f"\nğŸ”¥ å¼€å§‹è®­ç»ƒ {MODEL_CONFIGS[model_key]['name']}")
    
    # æ¸…ç†GPUå†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.reset_peak_memory_stats()
    
    # åˆ›å»ºæ¨¡å‹
    model = MODEL_CONFIGS[model_key]['create_fn']()
    model = model.to(DEVICE)
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)
    
    # æ··åˆç²¾åº¦è®­ç»ƒ - ä¼˜åŒ–è®¾ç½®
    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP) if USE_AMP else None
    
    # è®­ç»ƒè®°å½•
    best_val_acc = 0
    patience_counter = 0
    train_losses, val_losses, val_accuracies = [], [], []
    train_accs, learning_rates = [], []
    start_time = time.time()
    
    for epoch in range(EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        
        for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Train]"):
            imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
            
            optimizer.zero_grad()
            
            if USE_AMP:
                with torch.cuda.amp.autocast():
                    outputs = model(imgs)
                    loss = criterion(outputs, labels)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(imgs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
            
            train_loss += loss.item()
            
            # æ¸…ç†æ˜¾å­˜
            del imgs, labels, outputs, loss
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        train_loss /= len(train_loader)
        train_losses.append(train_loss)
        
        # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
        model.eval()
        train_correct = 0
        train_total = 0
        with torch.no_grad():
            for imgs, labels in train_loader:
                imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
                if USE_AMP:
                    with torch.cuda.amp.autocast():
                        outputs = model(imgs)
                else:
                    outputs = model(imgs)
                _, predicted = torch.max(outputs, 1)
                train_correct += (predicted == labels).sum().item()
                train_total += labels.size(0)
                del imgs, labels, outputs
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        train_acc = train_correct / train_total
        train_accs.append(train_acc)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for imgs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{EPOCHS} [Val]"):
                imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
                
                if USE_AMP:
                    with torch.cuda.amp.autocast():
                        outputs = model(imgs)
                        loss = criterion(outputs, labels)
                else:
                    outputs = model(imgs)
                    loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                
                _, predicted = torch.max(outputs, 1)
                correct += (predicted == labels).sum().item()
                total += labels.size(0)
                
                # æ¸…ç†æ˜¾å­˜
                del imgs, labels, outputs, loss
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        val_loss /= len(val_loader)
        val_acc = correct / total
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)
        
        scheduler.step(val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        learning_rates.append(current_lr)
        
        print(f"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, LR: {current_lr:.6f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            patience_counter = 0
            torch.save(model.state_dict(), save_path)
            print(f"âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ŒéªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
        else:
            patience_counter += 1
            if patience_counter >= PATIENCE:
                print("â›” Early stopping triggered")
                break
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    training_time = time.time() - start_time
    
    return {
        'best_acc': best_val_acc,
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_accs': train_accs,
        'val_accs': val_accuracies,
        'learning_rates': learning_rates,
        'training_time': training_time
    }

# Cell 7: é›†æˆé¢„æµ‹å‡½æ•°
def load_trained_models(model_paths):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    models_dict = {}
    for model_key, path in model_paths.items():
        if os.path.exists(path):
            model = MODEL_CONFIGS[model_key]['create_fn']()
            model.load_state_dict(torch.load(path, map_location=DEVICE))
            model = model.to(DEVICE)
            model.eval()
            models_dict[model_key] = model
            print(f"âœ… å·²åŠ è½½ {MODEL_CONFIGS[model_key]['name']}")
        else:
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    return models_dict

def ensemble_predict(models_dict, data_loader, voting_type='soft', weights=None):
    """é›†æˆé¢„æµ‹ (æ˜¾å­˜ä¼˜åŒ–ç‰ˆ)"""
    all_predictions = []
    all_labels = []
    model_outputs = {key: [] for key in models_dict.keys()}
    
    # å¦‚æœæ˜¯åŠ æƒæŠ•ç¥¨ä½†æ²¡æœ‰æä¾›æƒé‡ï¼Œåˆ™ä½¿ç”¨ç­‰æƒé‡
    if voting_type == 'weighted' and weights is None:
        weights = {key: 1.0 for key in models_dict.keys()}
    
    with torch.no_grad():
        for imgs, labels in tqdm(data_loader, desc="é›†æˆé¢„æµ‹"):
            imgs, labels = imgs.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)
            
            # æ”¶é›†æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹
            batch_predictions = []
            for model_key, model in models_dict.items():
                if USE_AMP:
                    with torch.cuda.amp.autocast():
                        outputs = model(imgs)
                else:
                    outputs = model(imgs)
                
                if voting_type in ['soft', 'weighted']:
                    probs = torch.softmax(outputs, dim=1)
                    batch_predictions.append(probs.cpu().numpy())
                else:  # hard voting
                    _, predicted = torch.max(outputs, 1)
                    batch_predictions.append(predicted.cpu().numpy())
                
                model_outputs[model_key].extend(outputs.cpu().numpy())
                del outputs
            
            # é›†æˆé¢„æµ‹
            if voting_type == 'soft':
                ensemble_probs = np.mean(batch_predictions, axis=0)
                ensemble_pred = np.argmax(ensemble_probs, axis=1)
            elif voting_type == 'weighted':
                weighted_probs = np.zeros_like(batch_predictions[0])
                total_weight = 0
                for i, (model_key, probs) in enumerate(zip(models_dict.keys(), batch_predictions)):
                    weight = weights[model_key]
                    weighted_probs += probs * weight
                    total_weight += weight
                ensemble_probs = weighted_probs / total_weight
                ensemble_pred = np.argmax(ensemble_probs, axis=1)
            else:
                batch_predictions = np.array(batch_predictions)
                ensemble_pred = []
                for i in range(batch_predictions.shape[1]):
                    votes = batch_predictions[:, i]
                    ensemble_pred.append(np.bincount(votes).argmax())
                ensemble_pred = np.array(ensemble_pred)
            
            all_predictions.extend(ensemble_pred)
            all_labels.extend(labels.cpu().numpy())
            
            # æ¸…ç†æ˜¾å­˜
            del imgs, labels
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    return np.array(all_predictions), np.array(all_labels), model_outputs

def calculate_model_weights(model_results, weight_method='accuracy'):
    """è®¡ç®—æ¨¡å‹æƒé‡"""
    weights = {}
    
    if weight_method == 'accuracy':
        # åŸºäºéªŒè¯å‡†ç¡®ç‡è®¡ç®—æƒé‡
        accuracies = {key: results['best_acc'] for key, results in model_results.items()}
        total_acc = sum(accuracies.values())
        
        for key, acc in accuracies.items():
            weights[key] = acc / total_acc
            
    elif weight_method == 'softmax':
        # ä½¿ç”¨softmaxå½’ä¸€åŒ–å‡†ç¡®ç‡ä½œä¸ºæƒé‡
        accuracies = np.array([results['best_acc'] for results in model_results.values()])
        softmax_weights = np.exp(accuracies * 10) / np.sum(np.exp(accuracies * 10))  # ä¹˜ä»¥10å¢å¼ºå·®å¼‚
        
        for i, key in enumerate(model_results.keys()):
            weights[key] = softmax_weights[i]
            
    elif weight_method == 'rank':
        # åŸºäºæ’åçš„æƒé‡åˆ†é…
        sorted_models = sorted(model_results.items(), key=lambda x: x[1]['best_acc'], reverse=True)
        n_models = len(sorted_models)
        
        for i, (key, _) in enumerate(sorted_models):
            weights[key] = (n_models - i) / sum(range(1, n_models + 1))
    
    return weights

def plot_training_history(model_results, save_dir='./works/plots'):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    os.makedirs(save_dir, exist_ok=True)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # ä¸ºæ¯ä¸ªæ¨¡å‹ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    for model_name, results in model_results.items():
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        epochs = range(1, len(results['train_losses']) + 1)
        
        # è®­ç»ƒå’ŒéªŒè¯æŸå¤±
        ax1.plot(epochs, results['train_losses'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        ax1.plot(epochs, results['val_losses'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
        ax1.set_title(f'{model_name} - æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡
        ax2.plot(epochs, results['train_accs'], 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
        ax2.plot(epochs, results['val_accs'], 'r-', label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)
        ax2.set_title(f'{model_name} - å‡†ç¡®ç‡æ›²çº¿', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # å­¦ä¹ ç‡å˜åŒ–
        ax3.plot(epochs, results['learning_rates'], 'g-', linewidth=2)
        ax3.set_title(f'{model_name} - å­¦ä¹ ç‡å˜åŒ–', fontsize=14, fontweight='bold')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Learning Rate')
        ax3.set_yscale('log')
        ax3.grid(True, alpha=0.3)
        
        # éªŒè¯å‡†ç¡®ç‡åˆ†å¸ƒ
        ax4.hist(results['val_accs'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        ax4.axvline(results['best_acc'], color='red', linestyle='--', linewidth=2, 
                   label=f'æœ€ä½³å‡†ç¡®ç‡: {results["best_acc"]:.4f}')
        ax4.set_title(f'{model_name} - éªŒè¯å‡†ç¡®ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax4.set_xlabel('Validation Accuracy')
        ax4.set_ylabel('Frequency')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, f'{model_name}_training_history.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    # ç»˜åˆ¶æ‰€æœ‰æ¨¡å‹çš„æ¯”è¾ƒå›¾
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    colors = ['blue', 'red', 'green', 'orange', 'purple']
    
    # éªŒè¯æŸå¤±æ¯”è¾ƒ
    for i, (model_name, results) in enumerate(model_results.items()):
        epochs = range(1, len(results['val_losses']) + 1)
        ax1.plot(epochs, results['val_losses'], color=colors[i % len(colors)], 
                label=model_name, linewidth=2)
    ax1.set_title('æ‰€æœ‰æ¨¡å‹éªŒè¯æŸå¤±æ¯”è¾ƒ', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Validation Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # éªŒè¯å‡†ç¡®ç‡æ¯”è¾ƒ
    for i, (model_name, results) in enumerate(model_results.items()):
        epochs = range(1, len(results['val_accs']) + 1)
        ax2.plot(epochs, results['val_accs'], color=colors[i % len(colors)], 
                label=model_name, linewidth=2)
    ax2.set_title('æ‰€æœ‰æ¨¡å‹éªŒè¯å‡†ç¡®ç‡æ¯”è¾ƒ', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Validation Accuracy')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # æœ€ä½³å‡†ç¡®ç‡æŸ±çŠ¶å›¾
    model_names = list(model_results.keys())
    best_accs = [results['best_acc'] for results in model_results.values()]
    bars = ax3.bar(model_names, best_accs, color=colors[:len(model_names)], alpha=0.7)
    ax3.set_title('å„æ¨¡å‹æœ€ä½³éªŒè¯å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
    ax3.set_ylabel('Best Validation Accuracy')
    ax3.set_ylim(0, 1)
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars, best_accs):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')
    ax3.grid(True, alpha=0.3, axis='y')
    
    # è®­ç»ƒæ—¶é—´æ¯”è¾ƒï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if 'training_time' in list(model_results.values())[0]:
        training_times = [results['training_time'] for results in model_results.values()]
        bars = ax4.bar(model_names, training_times, color=colors[:len(model_names)], alpha=0.7)
        ax4.set_title('å„æ¨¡å‹è®­ç»ƒæ—¶é—´', fontsize=14, fontweight='bold')
        ax4.set_ylabel('Training Time (seconds)')
        
        for bar, time in zip(bars, training_times):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + max(training_times)*0.01,
                    f'{time:.1f}s', ha='center', va='bottom', fontweight='bold')
        ax4.grid(True, alpha=0.3, axis='y')
    else:
        ax4.text(0.5, 0.5, 'è®­ç»ƒæ—¶é—´æ•°æ®ä¸å¯ç”¨', ha='center', va='center', 
                transform=ax4.transAxes, fontsize=12)
        ax4.set_title('è®­ç»ƒæ—¶é—´', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'models_comparison.png'), 
               dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜åˆ° {save_dir}")

def plot_confusion_matrix(y_true, y_pred, class_names, title, save_path=None):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
    from sklearn.metrics import confusion_matrix
    import seaborn as sns
    
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names)
    plt.title(title, fontsize=16, fontweight='bold')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
    plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
    else:
        plt.show()

def plot_ensemble_analysis(model_outputs, y_true, y_pred, class_names, save_dir='./works/plots'):
    """ç»˜åˆ¶é›†æˆåˆ†æå›¾"""
    os.makedirs(save_dir, exist_ok=True)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # æ¨¡å‹é¢„æµ‹ä¸€è‡´æ€§åˆ†æ
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. å„æ¨¡å‹é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
    ax1 = axes[0, 0]
    for model_name, outputs in model_outputs.items():
        outputs_array = np.array(outputs)
        probs = torch.softmax(torch.tensor(outputs_array), dim=1).numpy()
        max_probs = np.max(probs, axis=1)
        ax1.hist(max_probs, alpha=0.6, label=model_name, bins=30)
    
    ax1.set_title('å„æ¨¡å‹æœ€å¤§é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    ax1.set_xlabel('æœ€å¤§é¢„æµ‹æ¦‚ç‡')
    ax1.set_ylabel('é¢‘æ¬¡')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. é¢„æµ‹ä¸€è‡´æ€§çƒ­å›¾
    ax2 = axes[0, 1]
    model_names = list(model_outputs.keys())
    n_models = len(model_names)
    consistency_matrix = np.zeros((n_models, n_models))
    
    for i, model1 in enumerate(model_names):
        for j, model2 in enumerate(model_names):
            if i != j:
                outputs1 = np.array(model_outputs[model1])
                outputs2 = np.array(model_outputs[model2])
                pred1 = np.argmax(outputs1, axis=1)
                pred2 = np.argmax(outputs2, axis=1)
                consistency = np.mean(pred1 == pred2)
                consistency_matrix[i, j] = consistency
            else:
                consistency_matrix[i, j] = 1.0
    
    im = ax2.imshow(consistency_matrix, cmap='RdYlBu', vmin=0, vmax=1)
    ax2.set_xticks(range(n_models))
    ax2.set_yticks(range(n_models))
    ax2.set_xticklabels(model_names, rotation=45)
    ax2.set_yticklabels(model_names)
    ax2.set_title('æ¨¡å‹é—´é¢„æµ‹ä¸€è‡´æ€§', fontsize=14, fontweight='bold')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i in range(n_models):
        for j in range(n_models):
            text = ax2.text(j, i, f'{consistency_matrix[i, j]:.3f}',
                           ha="center", va="center", color="black", fontweight='bold')
    
    plt.colorbar(im, ax=ax2)
    
    # 3. é›†æˆé¢„æµ‹ç½®ä¿¡åº¦åˆ†æ
    ax3 = axes[1, 0]
    
    # è®¡ç®—é›†æˆé¢„æµ‹çš„ç½®ä¿¡åº¦
    ensemble_outputs = np.mean([np.array(outputs) for outputs in model_outputs.values()], axis=0)
    ensemble_probs = torch.softmax(torch.tensor(ensemble_outputs), dim=1).numpy()
    ensemble_confidence = np.max(ensemble_probs, axis=1)
    
    # æŒ‰æ­£ç¡®/é”™è¯¯é¢„æµ‹åˆ†ç»„
    correct_mask = (y_pred == y_true)
    correct_confidence = ensemble_confidence[correct_mask]
    wrong_confidence = ensemble_confidence[~correct_mask]
    
    ax3.hist(correct_confidence, alpha=0.7, label=f'æ­£ç¡®é¢„æµ‹ ({len(correct_confidence)})', 
             bins=30, color='green')
    ax3.hist(wrong_confidence, alpha=0.7, label=f'é”™è¯¯é¢„æµ‹ ({len(wrong_confidence)})', 
             bins=30, color='red')
    
    ax3.set_title('é›†æˆé¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    ax3.set_xlabel('é¢„æµ‹ç½®ä¿¡åº¦')
    ax3.set_ylabel('é¢‘æ¬¡')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ç±»åˆ«é¢„æµ‹å‡†ç¡®ç‡
    ax4 = axes[1, 1]
    from sklearn.metrics import classification_report
    
    class_accuracies = []
    for i, class_name in enumerate(class_names):
        class_mask = (y_true == i)
        if np.sum(class_mask) > 0:
            class_acc = np.mean(y_pred[class_mask] == y_true[class_mask])
            class_accuracies.append(class_acc)
        else:
            class_accuracies.append(0)
    
    bars = ax4.bar(class_names, class_accuracies, color=['skyblue', 'lightcoral'])
    ax4.set_title('å„ç±»åˆ«é¢„æµ‹å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
    ax4.set_ylabel('å‡†ç¡®ç‡')
    ax4.set_ylim(0, 1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars, class_accuracies):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
    
    ax4.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, 'ensemble_analysis.png'), 
               dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"é›†æˆåˆ†æå›¾è¡¨å·²ä¿å­˜åˆ° {save_dir}")

# Cell 8: ä¸»è®­ç»ƒæµç¨‹
def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    print("ğŸ“‚ åŠ è½½æ•°æ®é›†...")
    
    # æ£€æŸ¥æ•°æ®è·¯å¾„
    if not os.path.exists(TRAIN_PATH) or not os.path.exists(VAL_PATH):
        print("âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·ä¿®æ”¹ BASE_PATH å˜é‡")
        print(f"å½“å‰è®­ç»ƒè·¯å¾„: {TRAIN_PATH}")
        print(f"å½“å‰éªŒè¯è·¯å¾„: {VAL_PATH}")
        return
    
    train_df = create_dataframe(TRAIN_PATH, "è®­ç»ƒ")
    val_df = create_dataframe(VAL_PATH, "éªŒè¯")
    
    if len(train_df) == 0 or len(val_df) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ–‡ä»¶æ ¼å¼")
        return
    
    # é™åˆ¶éªŒè¯é›†å¤§å°ä»¥èŠ‚çœæ˜¾å­˜
    MAX_VAL_SAMPLES = 3200
    if len(val_df) > MAX_VAL_SAMPLES:
        print(f"âš ï¸ éªŒè¯é›†è¿‡å¤§ ({len(val_df)} å¼ )ï¼Œéšæœºé‡‡æ · {MAX_VAL_SAMPLES} å¼ å›¾ç‰‡")
        val_df = val_df.groupby('label', group_keys=False).apply(
            lambda x: x.sample(min(len(x), MAX_VAL_SAMPLES//2), random_state=42)
        ).reset_index(drop=True)
        print(f"âœ… éªŒè¯é›†é‡‡æ ·å®Œæˆï¼Œå½“å‰å¤§å°: {len(val_df)}")
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨ (ä¼˜åŒ–GPUåˆ©ç”¨ç‡)
    train_dataset = DeepfakeDataset(train_df, transform=train_transform)
    val_dataset = DeepfakeDataset(val_df, transform=val_transform)
    
    # ä¼˜åŒ–æ•°æ®åŠ è½½å™¨è®¾ç½®ä»¥æ›´å¥½åˆ©ç”¨GPU
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
                             num_workers=NUM_WORKERS, pin_memory=True, drop_last=True,
                             persistent_workers=True, prefetch_factor=2)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
                           num_workers=NUM_WORKERS, pin_memory=True,
                           persistent_workers=True, prefetch_factor=2)
    
    print(f"\nğŸ“Š æ•°æ®é›†æ€»è§ˆ:")
    print(f"è®­ç»ƒé›†æ€»æ•°: {len(train_df)}")
    print(f"éªŒè¯é›†æ€»æ•°: {len(val_df)}")
    print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
    
    # åªåœ¨ç¬¬ä¸€æ¬¡æ˜¾ç¤ºGPUç›¸å…³å‚æ•°
    if not hasattr(torch, '_deepfake_dataset_info_shown'):
        print(f"å›¾åƒå°ºå¯¸: {IMG_SIZE}x{IMG_SIZE}")
        print(f"æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
        print(f"æ•°æ®åŠ è½½çº¿ç¨‹: {NUM_WORKERS}")
        torch._deepfake_dataset_info_shown = True
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    print("\nğŸš€ å¼€å§‹è®­ç»ƒå¤šä¸ªæ¨¡å‹...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = './works'
    os.makedirs(output_dir, exist_ok=True)
    
    # é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹ (è½»é‡åŒ–ç»„åˆ)
    selected_models = ['efficientnet_b0', 'resnet18','convnext_tiny']
    model_paths = {}
    model_results = {}
    
    for model_key in selected_models:
        save_path = os.path.join(output_dir, f"best_{model_key}_model_local.pth")
        model_paths[model_key] = save_path
        
        print(f"\n{'='*50}")
        print(f"è®­ç»ƒæ¨¡å‹: {MODEL_CONFIGS[model_key]['name']}")
        print(f"{'='*50}")
        
        result = train_single_model(
            model_key, train_loader, val_loader, save_path
        )
        
        model_results[model_key] = result
        
        print(f"âœ… {MODEL_CONFIGS[model_key]['name']} è®­ç»ƒå®Œæˆï¼Œæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {result['best_acc']:.4f}")
        
        # å¼ºåˆ¶æ¸…ç†æ˜¾å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    # é›†æˆé¢„æµ‹å’Œè¯„ä¼°
    print("\nğŸ”® å¼€å§‹é›†æˆé¢„æµ‹...")
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    trained_models = load_trained_models(model_paths)
    
    if len(trained_models) == 0:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡å‹")
        return
    
    # è®¡ç®—æ¨¡å‹æƒé‡
    model_weights = calculate_model_weights(model_results, weight_method='accuracy')
    print("\nâš–ï¸ æ¨¡å‹æƒé‡åˆ†é…:")
    for model_key, weight in model_weights.items():
        print(f"  {MODEL_CONFIGS[model_key]['name']:20}: {weight:.4f}")
    
    # è½¯æŠ•ç¥¨é¢„æµ‹
    print("\nğŸ“Š è½¯æŠ•ç¥¨é›†æˆé¢„æµ‹:")
    soft_predictions, true_labels, val_model_outputs = ensemble_predict(trained_models, val_loader, voting_type='soft')
    soft_accuracy = accuracy_score(true_labels, soft_predictions)
    print(f"è½¯æŠ•ç¥¨å‡†ç¡®ç‡: {soft_accuracy:.4f}")
    
    # ç¡¬æŠ•ç¥¨é¢„æµ‹
    print("\nğŸ“Š ç¡¬æŠ•ç¥¨é›†æˆé¢„æµ‹:")
    hard_predictions, _, _ = ensemble_predict(trained_models, val_loader, voting_type='hard')
    hard_accuracy = accuracy_score(true_labels, hard_predictions)
    print(f"ç¡¬æŠ•ç¥¨å‡†ç¡®ç‡: {hard_accuracy:.4f}")
    
    # åŠ æƒæŠ•ç¥¨é¢„æµ‹
    print("\nğŸ“Š åŠ æƒæŠ•ç¥¨é›†æˆé¢„æµ‹:")
    weighted_predictions, _, _ = ensemble_predict(trained_models, val_loader, voting_type='weighted', weights=model_weights)
    weighted_accuracy = accuracy_score(true_labels, weighted_predictions)
    print(f"åŠ æƒæŠ•ç¥¨å‡†ç¡®ç‡: {weighted_accuracy:.4f}")
    
    # å¯è§†åŒ–
    print("\n" + "="*50)
    print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("="*50)
    
    # åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
    plots_dir = os.path.join(output_dir, 'plots')
    os.makedirs(plots_dir, exist_ok=True)
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    plot_training_history(model_results, save_dir=plots_dir)
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    class_names = ['Real', 'Fake']
    plot_confusion_matrix(true_labels, soft_predictions, class_names, 
                         'é›†æˆæ¨¡å‹æ··æ·†çŸ©é˜µ', 
                         save_path=os.path.join(plots_dir, 'ensemble_confusion_matrix.png'))
    
    # ç»˜åˆ¶é›†æˆåˆ†æ
    plot_ensemble_analysis(val_model_outputs, true_labels, soft_predictions, 
                          class_names, save_dir=plots_dir)
    
    # ç»“æœæ€»ç»“
    print("\n" + "="*60)
    print("ğŸ‰ å¤šæ¨¡å‹é›†æˆè®­ç»ƒå®Œæˆï¼")
    print("="*60)
    print(f"è®­ç»ƒçš„æ¨¡å‹æ•°é‡: {len(selected_models)}")
    
    for model_key in selected_models:
        best_acc = model_results[model_key]['best_acc']
        print(f"{MODEL_CONFIGS[model_key]['name']:20}: {best_acc:.4f}")
    
    print(f"{'è½¯æŠ•ç¥¨é›†æˆ':20}: {soft_accuracy:.4f}")
    print(f"{'ç¡¬æŠ•ç¥¨é›†æˆ':20}: {hard_accuracy:.4f}")
    print(f"{'åŠ æƒæŠ•ç¥¨é›†æˆ':20}: {weighted_accuracy:.4f}")
    
    # æ‰¾å‡ºæœ€ä½³æ–¹æ³•
    best_single = max([results['best_acc'] for results in model_results.values()])
    ensemble_results = {
        'è½¯æŠ•ç¥¨': soft_accuracy,
        'ç¡¬æŠ•ç¥¨': hard_accuracy,
        'åŠ æƒæŠ•ç¥¨': weighted_accuracy
    }
    best_ensemble = max(ensemble_results, key=ensemble_results.get)
    
    print(f"\nğŸ† æœ€ä½³å•æ¨¡å‹å‡†ç¡®ç‡: {best_single:.4f}")
    print(f"ğŸ† æœ€ä½³é›†æˆæ–¹æ³•: {best_ensemble} (å‡†ç¡®ç‡: {ensemble_results[best_ensemble]:.4f})")
    
    improvement = (ensemble_results[best_ensemble] - best_single) * 100
    print(f"ğŸš€ é›†æˆæå‡: {improvement:+.2f}%")
    
    print(f"\nğŸ’¾ ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶:")
    for model_key, path in model_paths.items():
        if os.path.exists(path):
            print(f"  âœ… {path}")
        else:
            print(f"  âŒ {path}")
    
    # ä¿å­˜ç»“æœ
    import json
    results = {
        'model_results': {k: {key: val for key, val in v.items() if key != 'model'} for k, v in model_results.items()},
        'ensemble_results': {
            'soft_voting': float(soft_accuracy),
            'hard_voting': float(hard_accuracy),
            'weighted_voting': float(weighted_accuracy)
        },
        'model_weights': model_weights
    }
    
    results_path = os.path.join(output_dir, 'ensemble_results_local.json')
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {results_path}")
    print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ° {plots_dir} ç›®å½•")

if __name__ == "__main__":
    main()